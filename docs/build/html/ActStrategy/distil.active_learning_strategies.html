

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Active Learning Strategies &mdash; DISTIL v0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="utils" href="distil.utils.html" />
    <link rel="prev" title="DISTIL" href="modules.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DISTIL
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">DISTIL</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Active Learning Strategies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.badge">BADGE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.core_set">Core-Set Approch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.entropy_sampling">Entropy Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.entropy_sampling_dropout">Entropy Sampling with Dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.fass">FASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.glister">GLISTER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.least_confidence">Least Confidence</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.least_confidence_dropout">Least Confidence with Dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.margin_sampling">Margin Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.margin_sampling_dropout">Margin sampling with Dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.random_sampling">Random Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.submod_sampling">Submodular Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.adversarial_bim">Adversarial BIM</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.adversarial_deepfool">Adversarial DeepFool</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.bayesian_active_learning_disagreement_dropout">Bayesian Active Learning Disagreement Dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.kmeans_sampling">KMeans Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-distil.active_learning_strategies.baseline_sampling">Baseline Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#references">REFERENCES</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distil.utils.html">utils</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DISTIL</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="modules.html">DISTIL</a> &raquo;</li>
        
      <li>Active Learning Strategies</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/ActStrategy/distil.active_learning_strategies.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="active-learning-strategies">
<h1>Active Learning Strategies<a class="headerlink" href="#active-learning-strategies" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-distil.active_learning_strategies.badge">
<span id="badge"></span><h2>BADGE<a class="headerlink" href="#module-distil.active_learning_strategies.badge" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.badge.BADGE">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.badge.</code><code class="sig-name descname">BADGE</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/badge.html#BADGE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.badge.BADGE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds (BADGE)
<a class="footnote-reference brackets" href="#dblp-journals-corr-abs-1906-03671" id="id1">1</a> Strategy. This class extends :
class:<cite>active_learning_strategies.strategy.Strategy</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Numpy array</em>) – Features of the labled set of points</p></li>
<li><p><strong>Y</strong> (<em>Numpy array</em>) – Lables of the labled set of points</p></li>
<li><p><strong>unlabeled_x</strong> (<em>Numpy array</em>) – Features of the unlabled set of points</p></li>
<li><p><strong>net</strong> (<em>class object</em>) – Model architecture used for training. Could be instance of models defined in <cite>distil.utils.models</cite> or something similar.</p></li>
<li><p><strong>handler</strong> (<em>class object</em>) – It should be a subclasses of torch.utils.data.Dataset i.e, have __getitem__ and __len__ methods implemented, so that is could be passed to pytorch DataLoader.Could be instance of handlers defined in <cite>distil.utils.DataHandler</cite> or something similar.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – No. of classes in tha dataset</p></li>
<li><p><strong>args</strong> (<em>dictionary</em>) – This dictionary should have ‘batch_size’ as a key.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.badge.BADGE.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/badge.html#BADGE.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.badge.BADGE.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>chosen</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="distil.active_learning_strategies.badge.BADGE.select_per_batch">
<code class="sig-name descname">select_per_batch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em>, <em class="sig-param"><span class="n">batch_size</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/badge.html#BADGE.select_per_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.badge.BADGE.select_per_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Select points to label by using per-batch BADGE strategy</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>budget</strong> (<em>int</em>) – Number of indices to be selected from unlabeled set</p></li>
<li><p><strong>batch_size</strong> (<em>TYPE</em>) – Size of batches to form</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>chosen</strong> – List of selected data point indices with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.core_set">
<span id="core-set-approch"></span><h2>Core-Set Approch<a class="headerlink" href="#module-distil.active_learning_strategies.core_set" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.core_set.CoreSet">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.core_set.</code><code class="sig-name descname">CoreSet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/core_set.html#CoreSet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.core_set.CoreSet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of CoreSet <a class="footnote-reference brackets" href="#sener2018active" id="id2">2</a> Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include coreset sampling technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.core_set.CoreSet.furthest_first">
<code class="sig-name descname">furthest_first</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">X_set</span></em>, <em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/core_set.html#CoreSet.furthest_first"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.core_set.CoreSet.furthest_first" title="Permalink to this definition">¶</a></dt>
<dd><p>Selects points with maximum distance</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Embeddings of unlabeled set</p></li>
<li><p><strong>X_set</strong> (<em>numpy array</em>) – Embeddings of labeled set</p></li>
<li><p><strong>n</strong> (<em>int</em>) – Number of points to return</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>idxs</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="distil.active_learning_strategies.core_set.CoreSet.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/core_set.html#CoreSet.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.core_set.CoreSet.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>chosen</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.entropy_sampling">
<span id="entropy-sampling"></span><h2>Entropy Sampling<a class="headerlink" href="#module-distil.active_learning_strategies.entropy_sampling" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.entropy_sampling.EntropySampling">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.entropy_sampling.</code><code class="sig-name descname">EntropySampling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/entropy_sampling.html#EntropySampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.entropy_sampling.EntropySampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Entropy Sampling Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include entropy sampling technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.entropy_sampling.EntropySampling.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/entropy_sampling.html#EntropySampling.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.entropy_sampling.EntropySampling.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>U_idx</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.entropy_sampling_dropout">
<span id="entropy-sampling-with-dropout"></span><h2>Entropy Sampling with Dropout<a class="headerlink" href="#module-distil.active_learning_strategies.entropy_sampling_dropout" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.entropy_sampling_dropout.EntropySamplingDropout">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.entropy_sampling_dropout.</code><code class="sig-name descname">EntropySamplingDropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/entropy_sampling_dropout.html#EntropySamplingDropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.entropy_sampling_dropout.EntropySamplingDropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Entropy Sampling Dropout Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include entropy sampling with dropout technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
<p>n_drop
Dropout value to be used (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.entropy_sampling_dropout.EntropySamplingDropout.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/entropy_sampling_dropout.html#EntropySamplingDropout.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.entropy_sampling_dropout.EntropySamplingDropout.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>U_idx</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.fass">
<span id="fass"></span><h2>FASS<a class="headerlink" href="#module-distil.active_learning_strategies.fass" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.fass.FASS">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.fass.</code><code class="sig-name descname">FASS</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/fass.html#FASS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.fass.FASS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of FASS strategy:footcite:<cite>pmlr-v37-wei15</cite> to select data points for active learning.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
<p>submod: str
Choice of submodular function - ‘facility_location’ | ‘graph_cut’ | ‘saturated_coverage’ | ‘sum_redundancy’ | ‘feature_based’</p>
<p>selection_type: str
Choice of selection strategy - ‘PerClass’ | ‘Supervised’</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.fass.FASS.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/fass.html#FASS.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.fass.FASS.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>return_indices</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.glister">
<span id="glister"></span><h2>GLISTER<a class="headerlink" href="#module-distil.active_learning_strategies.glister" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.glister.GLISTER">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.glister.</code><code class="sig-name descname">GLISTER</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">valid</span></em>, <em class="sig-param"><span class="n">X_val</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Y_val</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">loss_criterion</span><span class="o">=</span><span class="default_value">CrossEntropyLoss()</span></em>, <em class="sig-param"><span class="n">typeOf</span><span class="o">=</span><span class="default_value">'none'</span></em>, <em class="sig-param"><span class="n">lam</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">kernel_batch_size</span><span class="o">=</span><span class="default_value">200</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/glister.html#GLISTER"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.glister.GLISTER" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of GLISTER-ACTIVE Strategy <a class="footnote-reference brackets" href="#killamsetty2020glister" id="id3">3</a>.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Numpy array</em>) – Features of the labled set of points</p></li>
<li><p><strong>Y</strong> (<em>Numpy array</em>) – Lables of the labled set of points</p></li>
<li><p><strong>unlabeled_x</strong> (<em>Numpy array</em>) – Features of the unlabled set of points</p></li>
<li><p><strong>net</strong> (<em>class object</em>) – Model architecture used for training. Could be instance of models defined in <cite>distil.utils.models</cite> or something similar.</p></li>
<li><p><strong>handler</strong> (<em>class object</em>) – It should be a subclass of torch.utils.data.Dataset i.e, have __getitem__ and __len__ methods implemented, so that is could be passed to pytorch DataLoader.Could be instance of handlers defined in <cite>distil.utils.DataHandler</cite> or something similar.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – No. of classes in tha dataset</p></li>
<li><p><strong>args</strong> (<em>dictionary</em>) – This dictionary should have keys ‘batch_size’ and  ‘lr’.
‘lr’ should be the learning rate used for training. ‘batch_size’  ‘batch_size’ should be such
that one can exploit the benefits of tensorization while honouring the resourse constraits.</p></li>
<li><p><strong>valid</strong> (<em>boolean</em>) – Whether validation set is passed or not</p></li>
<li><p><strong>X_val</strong> (<em>Numpy array</em><em>, </em><em>optional</em>) – Features of the points in the validation set. Mandatory if <cite>valid=True</cite>.</p></li>
<li><p><strong>Y_val</strong> (<em>Numpy array</em><em>, </em><em>optional</em>) – Lables of the points in the validation set. Mandatory if <cite>valid=True</cite>.</p></li>
<li><p><strong>loss_criterion</strong> (<em>class object</em><em>, </em><em>optional</em>) – The type of loss criterion. Default is <strong>torch.nn.CrossEntropyLoss()</strong></p></li>
<li><p><strong>typeOf</strong> (<em>str</em><em>, </em><em>optional</em>) – Determines the type of regulariser to be used. Default is <strong>‘none’</strong>.
For random regulariser use <strong>‘Rand’</strong>.
To use Facility Location set functiom as a regulariser use <strong>‘FacLoc’</strong>.
To use Diversity set functiom as a regulariser use <strong>‘Diversity’</strong>.</p></li>
<li><p><strong>lam</strong> (<em>float</em><em>, </em><em>optional</em>) – Determines the amount of regularisation to be applied. Mandatory if is not <cite>typeOf=’none’</cite> and by default set to <cite>None</cite>.
For random regulariser use values should be between 0 and 1 as it determines fraction of points replaced by random points.
For both ‘Diversity’ and ‘FacLoc’, <cite>lam</cite> determines the weightage given to them while computing the gain.</p></li>
<li><p><strong>kernel_batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – For ‘Diversity’ and ‘FacLoc’ regualrizer versions, similarity kernel is to be computed, which
entails creating a 3d torch tensor of dimenssions kernel_batch_size*kernel_batch_size*
feature dimenssion.Again kernel_batch_size should be such that one can exploit the benefits of
tensorization while honouring the resourse constraits.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.glister.GLISTER.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/glister.html#GLISTER.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.glister.GLISTER.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>chosen</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.least_confidence">
<span id="least-confidence"></span><h2>Least Confidence<a class="headerlink" href="#module-distil.active_learning_strategies.least_confidence" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.least_confidence.LeastConfidence">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.least_confidence.</code><code class="sig-name descname">LeastConfidence</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/least_confidence.html#LeastConfidence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.least_confidence.LeastConfidence" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Least Confidence Sampling Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code> to include least confidence technique to select data points for active learning.</p>
<p>In this active learning strategy, the algorithm selects the data points for which the model has the lowest confidence while predicting its hypothesised label.</p>
<table class="colwidths-given docutils align-default" id="id6">
<caption><span class="caption-text">Example</span><a class="headerlink" href="#id6" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Data Instances</p></th>
<th class="head"><p>Label 1</p></th>
<th class="head"><p>Label 2</p></th>
<th class="head"><p>Label 3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>p1</p></td>
<td><p>0.1</p></td>
<td><p>0.55</p></td>
<td><p>0.45</p></td>
</tr>
<tr class="row-odd"><td><p>p2</p></td>
<td><p>0.2</p></td>
<td><p>0.3</p></td>
<td><p>0.5</p></td>
</tr>
<tr class="row-even"><td><p>p3</p></td>
<td><p>0.1</p></td>
<td><p>0.1</p></td>
<td><p>0.8</p></td>
</tr>
</tbody>
</table>
<p>From the above table, the label for instance p1 is 2 with a confidence of 0.55, for instance p2, the hypothesised label predicted is 3 with confidence of 0.5 and for p3 label 3 is predicted with a confidence of 0.8. Thus, according to least confidence strategy,  the point for which it will query for true label will be instance p2.</p>
<p>Let pi represent probability for ith label and let there be n possible labels for data instance p then, mathematically it can be written as:</p>
<div class="math notranslate nohighlight">
\[\min{(\max{(P)})}\]</div>
<p>where P=[p1, p2,… pn]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.least_confidence.LeastConfidence.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/least_confidence.html#LeastConfidence.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.least_confidence.LeastConfidence.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Nuber of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>U_idx</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.least_confidence_dropout">
<span id="least-confidence-with-dropout"></span><h2>Least Confidence with Dropout<a class="headerlink" href="#module-distil.active_learning_strategies.least_confidence_dropout" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.least_confidence_dropout.LeastConfidenceDropout">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.least_confidence_dropout.</code><code class="sig-name descname">LeastConfidenceDropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/least_confidence_dropout.html#LeastConfidenceDropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.least_confidence_dropout.LeastConfidenceDropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Least Confidence Dropout Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include least confidence dropout technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
<p>n_drop
Dropout value to be used (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.least_confidence_dropout.LeastConfidenceDropout.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/least_confidence_dropout.html#LeastConfidenceDropout.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.least_confidence_dropout.LeastConfidenceDropout.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Nuber of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>U_idx</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.margin_sampling">
<span id="margin-sampling"></span><h2>Margin Sampling<a class="headerlink" href="#module-distil.active_learning_strategies.margin_sampling" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.margin_sampling.MarginSampling">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.margin_sampling.</code><code class="sig-name descname">MarginSampling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/margin_sampling.html#MarginSampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.margin_sampling.MarginSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Margin Sampling Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include margin sampling technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.margin_sampling.MarginSampling.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/margin_sampling.html#MarginSampling.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.margin_sampling.MarginSampling.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>U_idx</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.margin_sampling_dropout">
<span id="margin-sampling-with-dropout"></span><h2>Margin sampling with Dropout<a class="headerlink" href="#module-distil.active_learning_strategies.margin_sampling_dropout" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.margin_sampling_dropout.MarginSamplingDropout">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.margin_sampling_dropout.</code><code class="sig-name descname">MarginSamplingDropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/margin_sampling_dropout.html#MarginSamplingDropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.margin_sampling_dropout.MarginSamplingDropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Margin Sampling Dropout Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include margin sampling dropout technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
<p>n_drop
Dropout value to be used (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.margin_sampling_dropout.MarginSamplingDropout.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/margin_sampling_dropout.html#MarginSamplingDropout.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.margin_sampling_dropout.MarginSamplingDropout.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>U_idx</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.random_sampling">
<span id="random-sampling"></span><h2>Random Sampling<a class="headerlink" href="#module-distil.active_learning_strategies.random_sampling" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.random_sampling.RandomSampling">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.random_sampling.</code><code class="sig-name descname">RandomSampling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/random_sampling.html#RandomSampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.random_sampling.RandomSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Random Sampling Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include random sampling technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.random_sampling.RandomSampling.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/random_sampling.html#RandomSampling.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.random_sampling.RandomSampling.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>rand_idx</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.submod_sampling">
<span id="submodular-sampling"></span><h2>Submodular Sampling<a class="headerlink" href="#module-distil.active_learning_strategies.submod_sampling" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.submod_sampling.SubmodSampling">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.submod_sampling.</code><code class="sig-name descname">SubmodSampling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">typeOf</span></em>, <em class="sig-param"><span class="n">selection_type</span></em>, <em class="sig-param"><span class="n">if_grad</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em>, <em class="sig-param"><span class="n">kernel_batch_size</span><span class="o">=</span><span class="default_value">200</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/submod_sampling.html#SubmodSampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.submod_sampling.SubmodSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Numpy array</em>) – Features of the labled set of points</p></li>
<li><p><strong>Y</strong> (<em>Numpy array</em>) – Lables of the labled set of points</p></li>
<li><p><strong>unlabeled_x</strong> (<em>Numpy array</em>) – Features of the unlabled set of points</p></li>
<li><p><strong>net</strong> (<em>class object</em>) – Model architecture used for training. Could be instance of models defined in <cite>distil.utils.models</cite> or something similar.</p></li>
<li><p><strong>handler</strong> (<em>class object</em>) – It should be a subclass of torch.utils.data.Dataset i.e, have __getitem__ and __len__ methods implemented, so that is could be passed to pytorch DataLoader.Could be instance of handlers defined in <cite>distil.utils.DataHandler</cite> or something similar.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – No. of classes in tha dataset</p></li>
<li><p><strong>typeOf</strong> (<em>str</em>) – Choice of submodular function - ‘facility_location’ | ‘graph_cut’ | ‘saturated_coverage’ | ‘sum_redundancy’ | ‘feature_based’            | ‘Disparity-min’ | ‘Disparity-sum’ | ‘DPP’</p></li>
<li><p><strong>selection_type</strong> (<em>str</em>) – selection strategy - ‘Full’ <a href="#id4"><span class="problematic" id="id5">|</span></a>’PerClass’ | ‘Supervised’</p></li>
<li><p><strong>if_grad</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Determines if gradients to be used for subset selection. Default is False.</p></li>
<li><p><strong>args</strong> (<em>dictionary</em>) – This dictionary should have keys ‘batch_size’ and  ‘lr’.
‘lr’ should be the learning rate used for training. ‘batch_size’  ‘batch_size’ should be such
that one</p></li>
<li><p><strong>kernel_batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – For ‘Diversity’ and ‘FacLoc’ regualrizer versions, similarity kernel is to be computed, which
entails creating a 3d torch tensor of dimenssions kernel_batch_size*kernel_batch_size*
feature dimenssion.Again kernel_batch_size should be such that one can exploit the benefits of
tensorization while honouring the resourse constraits.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.submod_sampling.SubmodSampling.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/submod_sampling.html#SubmodSampling.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.submod_sampling.SubmodSampling.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>chosen</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.adversarial_bim">
<span id="adversarial-bim"></span><h2>Adversarial BIM<a class="headerlink" href="#module-distil.active_learning_strategies.adversarial_bim" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.adversarial_bim.AdversarialBIM">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.adversarial_bim.</code><code class="sig-name descname">AdversarialBIM</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/adversarial_bim.html#AdversarialBIM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.adversarial_bim.AdversarialBIM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<dl class="py method">
<dt id="distil.active_learning_strategies.adversarial_bim.AdversarialBIM.cal_dis">
<code class="sig-name descname">cal_dis</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/adversarial_bim.html#AdversarialBIM.cal_dis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.adversarial_bim.AdversarialBIM.cal_dis" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="distil.active_learning_strategies.adversarial_bim.AdversarialBIM.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/adversarial_bim.html#AdversarialBIM.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.adversarial_bim.AdversarialBIM.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>idxs</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.adversarial_deepfool">
<span id="adversarial-deepfool"></span><h2>Adversarial DeepFool<a class="headerlink" href="#module-distil.active_learning_strategies.adversarial_deepfool" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.adversarial_deepfool.AdversarialDeepFool">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.adversarial_deepfool.</code><code class="sig-name descname">AdversarialDeepFool</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/adversarial_deepfool.html#AdversarialDeepFool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.adversarial_deepfool.AdversarialDeepFool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Adversial Deep Fool Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include entropy sampling technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
<p>max_iter
Maximum Number of Iterations (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.adversarial_deepfool.AdversarialDeepFool.cal_dis">
<code class="sig-name descname">cal_dis</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/adversarial_deepfool.html#AdversarialDeepFool.cal_dis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.adversarial_deepfool.AdversarialDeepFool.cal_dis" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="distil.active_learning_strategies.adversarial_deepfool.AdversarialDeepFool.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/adversarial_deepfool.html#AdversarialDeepFool.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.adversarial_deepfool.AdversarialDeepFool.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>idxs</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.bayesian_active_learning_disagreement_dropout">
<span id="bayesian-active-learning-disagreement-dropout"></span><h2>Bayesian Active Learning Disagreement Dropout<a class="headerlink" href="#module-distil.active_learning_strategies.bayesian_active_learning_disagreement_dropout" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.bayesian_active_learning_disagreement_dropout.BALDDropout">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.bayesian_active_learning_disagreement_dropout.</code><code class="sig-name descname">BALDDropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/bayesian_active_learning_disagreement_dropout.html#BALDDropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.bayesian_active_learning_disagreement_dropout.BALDDropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of BALDDropout Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include entropy sampling technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
<p>n_drop
Dropout value to be used (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.bayesian_active_learning_disagreement_dropout.BALDDropout.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/bayesian_active_learning_disagreement_dropout.html#BALDDropout.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.bayesian_active_learning_disagreement_dropout.BALDDropout.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>idxs</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.kmeans_sampling">
<span id="kmeans-sampling"></span><h2>KMeans Sampling<a class="headerlink" href="#module-distil.active_learning_strategies.kmeans_sampling" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.kmeans_sampling.KMeansSampling">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.kmeans_sampling.</code><code class="sig-name descname">KMeansSampling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/kmeans_sampling.html#KMeansSampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.kmeans_sampling.KMeansSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of KMeans Sampling Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include entropy sampling technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.kmeans_sampling.KMeansSampling.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/kmeans_sampling.html#KMeansSampling.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.kmeans_sampling.KMeansSampling.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Nuber of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>q_idxs</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-distil.active_learning_strategies.baseline_sampling">
<span id="baseline-sampling"></span><h2>Baseline Sampling<a class="headerlink" href="#module-distil.active_learning_strategies.baseline_sampling" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="distil.active_learning_strategies.baseline_sampling.BaselineSampling">
<em class="property">class </em><code class="sig-prename descclassname">distil.active_learning_strategies.baseline_sampling.</code><code class="sig-name descname">BaselineSampling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">unlabeled_x</span></em>, <em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">handler</span></em>, <em class="sig-param"><span class="n">nclasses</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/baseline_sampling.html#BaselineSampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.baseline_sampling.BaselineSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">distil.active_learning_strategies.strategy.Strategy</span></code></p>
<p>Implementation of Baseline Sampling Strategy.
This class extends <code class="xref py py-class docutils literal notranslate"><span class="pre">active_learning_strategies.strategy.Strategy</span></code>
to include entropy sampling technique to select data points for active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – Present training/labeled data</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels of present training data</p></li>
<li><p><strong>unlabeled_x</strong> (<em>numpy array</em>) – Data without labels</p></li>
<li><p><strong>net</strong> (<em>class</em>) – Pytorch Model class</p></li>
<li><p><strong>handler</strong> (<em>class</em>) – Data Handler, which can load data even without labels.</p></li>
<li><p><strong>nclasses</strong> (<em>int</em>) – Number of unique target variables</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – <p>Specify optional parameters</p>
<p>batch_size
Batch size to be used inside strategy class (int, optional)</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="distil.active_learning_strategies.baseline_sampling.BaselineSampling.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">budget</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/baseline_sampling.html#BaselineSampling.select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.baseline_sampling.BaselineSampling.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Select next set of points</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>budget</strong> (<em>int</em>) – Number of indexes to be returned for next set</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>chosen</strong> – List of selected data point indexes with respect to unlabeled_x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="distil.active_learning_strategies.baseline_sampling.gram_aug">
<code class="sig-prename descclassname">distil.active_learning_strategies.baseline_sampling.</code><code class="sig-name descname">gram_aug</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">L_Y</span></em>, <em class="sig-param"><span class="n">L_Y_inv</span></em>, <em class="sig-param"><span class="n">b_u</span></em>, <em class="sig-param"><span class="n">c_u</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/baseline_sampling.html#gram_aug"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.baseline_sampling.gram_aug" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="distil.active_learning_strategies.baseline_sampling.gram_red">
<code class="sig-prename descclassname">distil.active_learning_strategies.baseline_sampling.</code><code class="sig-name descname">gram_red</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">L</span></em>, <em class="sig-param"><span class="n">L_inv</span></em>, <em class="sig-param"><span class="n">u_loc</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/baseline_sampling.html#gram_red"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.baseline_sampling.gram_red" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="distil.active_learning_strategies.baseline_sampling.sample_k_imp">
<code class="sig-prename descclassname">distil.active_learning_strategies.baseline_sampling.</code><code class="sig-name descname">sample_k_imp</code><span class="sig-paren">(</span><em class="sig-param">Phi</em>, <em class="sig-param">k</em>, <em class="sig-param">max_iter</em>, <em class="sig-param">rng=&lt;module 'numpy.random' from 'r:\\virtualenv\\alt_badge\\lib\\site-packages\\numpy\\random\\__init__.py'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/distil/active_learning_strategies/baseline_sampling.html#sample_k_imp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#distil.active_learning_strategies.baseline_sampling.sample_k_imp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="references">
<h2>REFERENCES<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="dblp-journals-corr-abs-1906-03671"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Jordan T. Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, and Alekh Agarwal. Deep batch active learning by diverse, uncertain gradient lower bounds. <em>CoRR</em>, 2019. URL: <a class="reference external" href="http://arxiv.org/abs/1906.03671">http://arxiv.org/abs/1906.03671</a>, <a class="reference external" href="https://arxiv.org/abs/1906.03671">arXiv:1906.03671</a>.</p>
</dd>
<dt class="label" id="sener2018active"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Ozan Sener and Silvio Savarese. Active learning for convolutional neural networks: a core-set approach. 2018. <a class="reference external" href="https://arxiv.org/abs/1708.00489">arXiv:1708.00489</a>.</p>
</dd>
<dt class="label" id="killamsetty2020glister"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Krishnateja Killamsetty, Durga Sivasubramanian, Ganesh Ramakrishnan, and Rishabh Iyer. Glister: generalization based data subset selection for efficient and robust learning. 2020. <a class="reference external" href="https://arxiv.org/abs/2012.10630">arXiv:2012.10630</a>.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="distil.utils.html" class="btn btn-neutral float-right" title="utils" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="modules.html" class="btn btn-neutral float-left" title="DISTIL" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Durga Sivasubramanian, Apurva Dani, Rishabh Iyer.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>