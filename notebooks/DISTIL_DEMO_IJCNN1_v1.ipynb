{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " DISTIL_DEMO_IJCNN1_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4vafrlTGa9-"
      },
      "source": [
        "# **DISTIL Installation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZnCocrUGgYD",
        "outputId": "0dadb96a-097c-4dd5-e20e-53e28da53949"
      },
      "source": [
        "!git clone https://github.com/decile-team/distil.git\n",
        "!git clone https://github.com/decile-team/datasets.git\n",
        "!pip install apricot-select\n",
        "%cd distil"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'distil'...\n",
            "remote: Enumerating objects: 2310, done.\u001b[K\n",
            "remote: Counting objects: 100% (230/230), done.\u001b[K\n",
            "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
            "remote: Total 2310 (delta 115), reused 112 (delta 61), pack-reused 2080\u001b[K\n",
            "Receiving objects: 100% (2310/2310), 14.98 MiB | 22.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1418/1418), done.\n",
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 16 (delta 3), reused 12 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n",
            "Collecting apricot-select\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/96/7d9aec6ab622449aad7556101e90c2ef67b72b7cf33ded6cc9326a41e169/apricot-select-0.6.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (0.51.2)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (4.41.1)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (56.0.0)\n",
            "Building wheels for collected packages: apricot-select\n",
            "  Building wheel for apricot-select (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apricot-select: filename=apricot_select-0.6.1-cp37-none-any.whl size=48789 sha256=0156349ecf6c7e3f7b0deada84bdec96973463a2f799117cadd7c23c84797b4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/53/c1/67fd7b8bd5be9d506fdac6bb9b73b5c69734da8210833998fa\n",
            "Successfully built apricot-select\n",
            "Installing collected packages: nose, apricot-select\n",
            "Successfully installed apricot-select-0.6.1 nose-1.3.7\n",
            "/content/distil\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPSV3mJ0Gjls"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS8dVJqpGjy0",
        "outputId": "eb51ad5b-77ac-44ac-f765-1eefaeb9dfe9"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "\n",
        "from distil.active_learning_strategies import GLISTER, BADGE, EntropySampling, RandomSampling, SubmodSampling\n",
        "from distil.utils.data_handler import DataHandler_Points\n",
        "from distil.utils.models.simple_net import TwoLayerNet\n",
        "from distil.utils.train_helper import data_train\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfv3T-zBGp6P"
      },
      "source": [
        "# **Data, Model & Directory Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seu_jbfIGvIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8f03cc-97a6-4143-f6a2-38ff1b1f937c"
      },
      "source": [
        "def libsvm_file_load(path,dim, save_data=False):\n",
        "    data = []\n",
        "    target = []\n",
        "    with open(path) as fp:\n",
        "       line = fp.readline()\n",
        "       while line:\n",
        "        temp = [i for i in line.strip().split(\" \")]\n",
        "        target.append(int(float(temp[0]))) # Class Number. # Not assumed to be in (0, K-1)\n",
        "        temp_data = [0]*dim\n",
        "        \n",
        "        for i in temp[1:]:\n",
        "            ind,val = i.split(':')\n",
        "            temp_data[int(ind)-1] = float(val)\n",
        "        data.append(temp_data)\n",
        "        line = fp.readline()\n",
        "    X_data = np.array(data,dtype=np.float32)\n",
        "    Y_label = np.array(target)\n",
        "    if save_data:\n",
        "        # Save the numpy files to the folder where they come from\n",
        "        data_np_path = path + '.data.npy'\n",
        "        target_np_path = path + '.label.npy'\n",
        "        np.save(data_np_path, X_data)\n",
        "        np.save(target_np_path, Y_label)\n",
        "    return (X_data, Y_label)\n",
        "\n",
        "    \n",
        "trn_file = '../datasets/ijcnn1/ijcnn1.trn'\n",
        "val_file = '../datasets/ijcnn1/ijcnn1.val'\n",
        "tst_file = '../datasets/ijcnn1/ijcnn1.tst'\n",
        "\n",
        "data_dims = 22\n",
        "nclasses = 2\n",
        "\n",
        "x_trn, y_trn = libsvm_file_load(trn_file, dim=data_dims)\n",
        "x_val, y_val = libsvm_file_load(val_file, dim=data_dims)\n",
        "x_tst, y_tst = libsvm_file_load(tst_file, dim=data_dims)\n",
        "\n",
        "print(np.unique(y_tst))\n",
        "\n",
        "# The class labels are (-1,1). Make them to (0,1)\n",
        "y_trn[y_trn < 0] = 0\n",
        "y_val[y_val < 0] = 0\n",
        "y_tst[y_tst < 0] = 0    \n",
        "\n",
        "sc = StandardScaler()\n",
        "x_trn = sc.fit_transform(x_trn)\n",
        "x_val = sc.transform(x_val)\n",
        "x_tst = sc.transform(x_tst)\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6qg8oIWG0g8",
        "outputId": "2f95d593-bc4a-4768-ec5a-f4fe7d4a7880"
      },
      "source": [
        "X_unlabeled = deepcopy(x_trn)\n",
        "y_unlabeled = deepcopy(y_trn)\n",
        "X_test = deepcopy(x_tst)\n",
        "y_test = deepcopy(y_tst)\n",
        "\n",
        "nSamps, dim = np.shape(X_unlabeled)\n",
        "\n",
        "np.random.seed(42)\n",
        "start_idxs = np.random.choice(nSamps, size=int(0.01*nSamps), replace=False)\n",
        "\n",
        "X_tr = X_unlabeled[start_idxs]\n",
        "X_unlabeled = np.delete(X_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "y_tr = y_unlabeled[start_idxs]\n",
        "y_unlabeled = np.delete(y_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "n_rounds = 10    ##Number of rounds to run ac\n",
        "budget = int(0.01*x_trn.shape[0]) \n",
        "handler = DataHandler_Points\n",
        "\n",
        "net = TwoLayerNet(data_dims, nclasses, 40)\n",
        "net.apply(init_weights)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TwoLayerNet(\n",
              "  (linear1): Linear(in_features=22, out_features=40, bias=True)\n",
              "  (linear2): Linear(in_features=40, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn13lujmHHqv"
      },
      "source": [
        "#Model Directory\n",
        "base_dir = \"/content/ijcnn1/\"\n",
        "os.makedirs(base_dir, exist_ok = True)\n",
        "model_directory = os.path.join(base_dir, 'base_model.pth')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eek6TzJFjtpl",
        "outputId": "e0b7775e-34a2-4fba-f3eb-75f0ec01aaa4"
      },
      "source": [
        "print(np.unique(y_tst))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTyDOxTAHRQl"
      },
      "source": [
        "# **Initial Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHuxnhOzHNws",
        "outputId": "bd1c0d1c-a90e-49c2-ef44-82d13c3d1d00"
      },
      "source": [
        "args = {'n_epoch':500, 'lr':float(0.1),'batch_size':128, 'max_accuracy':0.99, 'window_size':20} \n",
        "dt = data_train(X_tr, y_tr, net, handler, args)\n",
        "clf = dt.train()\n",
        "torch.save(clf.state_dict(), model_directory)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training..\n",
            "Epoch: 38 Training accuracy: 0.991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaZS0_O3Hr8A"
      },
      "source": [
        "# **Load Base Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmos4kJnHrfQ"
      },
      "source": [
        "net.load_state_dict(torch.load(model_directory))\n",
        "clf = net"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBkdgCrYIR3v"
      },
      "source": [
        "# **Random**\n",
        "This strategy is often used as a baseline, where we pick a set of unlabled points randomly. Here we create a instance of distil.active_learning_strategies.random_sampling.RandomSampling by passig following parameters:\n",
        "\n",
        "**X (Numpy array)** – Features of the labled set of points\n",
        "\n",
        "**Y (Numpy array)** – Lables of the labled set of points\n",
        "\n",
        "**unlabeled_x (Numpy array)** – Features of the unlabled set of points\n",
        "\n",
        "**net (class object)** – Model architecture used for training. Could be instance of models defined in distil.utils.models or something similar.\n",
        "\n",
        "**handler (class object)** – It should be a subclass of torch.utils.data.Dataset i.e, have __getitem__ and __len__ methods implemented, so that is could be passed to pytorch DataLoader.Could be instance of handlers defined in distil.utils.DataHandler or something similar.\n",
        "\n",
        "**nclasses (int)** – No. of classes in tha dataset\n",
        "\n",
        "**args (dictionary)**– This dictionary should have ‘batch_size’ as a key. 'batch_size' should be such that one can exploit the benefits of tensorization while honouring the resourse constraits. This ‘batch_size’ therefore can be different than the one used for training.\n",
        "\n",
        "We initally pass None for X,Y and unlabeled_x. Later we update using update functions of training class and RandomSampling class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXPxaYf0ISJN",
        "outputId": "00bd37ad-b8ec-484b-ad2c-8bab24fa603c"
      },
      "source": [
        "#Initializing Strategy Class\n",
        "strategy_args = {'batch_size' : 128, 'lr':float(0.1)}\n",
        "strategy = RandomSampling(X_tr, y_tr, X_unlabeled, net, handler, nclasses, strategy_args)\n",
        "\n",
        "#Initial Training\n",
        "args = {'n_epoch':500, 'lr':float(0.1),'batch_size':128, 'max_accuracy':0.99, 'window_size':20} \n",
        "dt = data_train(X_tr, y_tr, clf, handler, args)\n",
        "\n",
        "#Updating the trained model in strategy class\n",
        "strategy.update_model(clf)\n",
        "\n",
        "# y_pred = strategy.predict(X_test).numpy()\n",
        "acc = np.zeros(n_rounds)\n",
        "acc[0] = dt.get_acc_on_set(X_test, y_test)\n",
        "print('Initial Testing accuracy:', round(acc[0]*100, 2), flush=True)\n",
        "\n",
        "##User Controlled Loop\n",
        "for rd in range(1, n_rounds):\n",
        "    print('-------------------------------------------------')\n",
        "    print('Round', rd) \n",
        "    print('-------------------------------------------------')\n",
        "\n",
        "    #Using select function for getting next set of data points\n",
        "    idx = strategy.select(budget)\n",
        "\n",
        "    #Saving state of model, since labeling new points might take time\n",
        "    strategy.save_state('./state.pkl')\n",
        "\n",
        "    #Adding new points to training set\n",
        "    X_tr = np.concatenate((X_tr, X_unlabeled[idx]), axis=0)\n",
        "    X_unlabeled = np.delete(X_unlabeled, idx, axis = 0)\n",
        "\n",
        "    #Human In Loop, Assuming user adds new labels here\n",
        "    y_tr = np.concatenate((y_tr, y_unlabeled[idx]), axis = 0)\n",
        "    y_unlabeled = np.delete(y_unlabeled, idx, axis = 0)\n",
        "    print('Number of training points -',X_tr.shape[0])\n",
        "\n",
        "    #Reload state and start training\n",
        "    strategy.load_state('./state.pkl')\n",
        "    strategy.update_data(X_tr, y_tr, X_unlabeled)\n",
        "    dt.update_data(X_tr, y_tr)\n",
        "\n",
        "    clf = dt.train()\n",
        "    strategy.update_model(clf)\n",
        "    acc[rd] = dt.get_acc_on_set(X_test, y_test)\n",
        "    print('Testing accuracy:', round(acc[rd]*100, 2), flush=True)\n",
        "    if acc[rd] > 0.98:\n",
        "        print('Testing accuracy reached above 98%, stopping training!')\n",
        "        break\n",
        "\n",
        "print('Training Completed')\n",
        "\n",
        "#Saving accuracies for further analysis\n",
        "with open(os.path.join(base_dir,'random.txt'), 'w') as f:\n",
        "    for item in acc:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Testing accuracy: 91.2\n",
            "-------------------------------------------------\n",
            "Round 1\n",
            "-------------------------------------------------\n",
            "Number of training points - 700\n",
            "Training..\n",
            "Epoch: 32 Training accuracy: 0.991\n",
            "Testing accuracy: 94.39\n",
            "-------------------------------------------------\n",
            "Round 2\n",
            "-------------------------------------------------\n",
            "Number of training points - 1050\n",
            "Training..\n",
            "Epoch: 34 Training accuracy: 0.99\n",
            "Testing accuracy: 95.33\n",
            "-------------------------------------------------\n",
            "Round 3\n",
            "-------------------------------------------------\n",
            "Number of training points - 1400\n",
            "Training..\n",
            "Epoch: 36 Training accuracy: 0.991\n",
            "Testing accuracy: 95.49\n",
            "-------------------------------------------------\n",
            "Round 4\n",
            "-------------------------------------------------\n",
            "Number of training points - 1750\n",
            "Training..\n",
            "Epoch: 28 Training accuracy: 0.99\n",
            "Testing accuracy: 96.24\n",
            "-------------------------------------------------\n",
            "Round 5\n",
            "-------------------------------------------------\n",
            "Number of training points - 2100\n",
            "Training..\n",
            "Epoch: 28 Training accuracy: 0.99\n",
            "Testing accuracy: 96.62\n",
            "-------------------------------------------------\n",
            "Round 6\n",
            "-------------------------------------------------\n",
            "Number of training points - 2450\n",
            "Training..\n",
            "Epoch: 27 Training accuracy: 0.991\n",
            "Testing accuracy: 96.74\n",
            "-------------------------------------------------\n",
            "Round 7\n",
            "-------------------------------------------------\n",
            "Number of training points - 2800\n",
            "Training..\n",
            "Epoch: 37 Training accuracy: 0.991\n",
            "Testing accuracy: 96.67\n",
            "-------------------------------------------------\n",
            "Round 8\n",
            "-------------------------------------------------\n",
            "Number of training points - 3150\n",
            "Training..\n",
            "Epoch: 49 Training accuracy: 0.99\n",
            "Testing accuracy: 96.11\n",
            "-------------------------------------------------\n",
            "Round 9\n",
            "-------------------------------------------------\n",
            "Number of training points - 3500\n",
            "Training..\n",
            "Epoch: 39 Training accuracy: 0.991\n",
            "Testing accuracy: 96.87\n",
            "Training Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBpuErWxAHCc"
      },
      "source": [
        "# **Uncertanity based Active learning Strategy**\n",
        "\n",
        "The most basic active learning strategy, where we select samples about which the model is most uncertain. To quantify the uncertainity we use entropy, therefore select points which have maximum entropy. Let $z_i$ be output from the model then the correponding softmax would be $$\\sigma(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}$$. Then entropy can be calculated as, $$ENTROPY = -\\sum_j \\sigma(z_j)*log(\\sigma(z_i))$$\n",
        "\n",
        "Here we create a instance of distil.active_learning_strategies.entropy_sampling.EntropySampling with same parameters passed to distil.active_learning_strategies.random_sampling.RandomSampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaknF2AU3OXN"
      },
      "source": [
        "**Reinitialize Model & Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA1IQYzu3O_O"
      },
      "source": [
        "X_unlabeled = deepcopy(x_trn)\n",
        "y_unlabeled = deepcopy(y_trn)\n",
        "X_test = deepcopy(x_tst)\n",
        "y_test = deepcopy(y_tst)\n",
        "\n",
        "nSamps, dim = np.shape(X_unlabeled)\n",
        "\n",
        "np.random.seed(42)\n",
        "start_idxs = np.random.choice(nSamps, size=int(0.01*nSamps), replace=False)\n",
        "\n",
        "X_tr = X_unlabeled[start_idxs]\n",
        "X_unlabeled = np.delete(X_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "y_tr = y_unlabeled[start_idxs]\n",
        "y_unlabeled = np.delete(y_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "n_rounds = 10    ##Number of rounds to run ac\n",
        "budget = int(0.01*x_trn.shape[0]) \n",
        "handler = DataHandler_Points\n",
        "\n",
        "net = TwoLayerNet(data_dims, nclasses, 40)\n",
        "net.apply(init_weights)\n",
        "\n",
        "net.load_state_dict(torch.load(model_directory))\n",
        "clf = net"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyPo_T10KJ51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ea15bf-1b6a-4453-be34-0cbd790926ed"
      },
      "source": [
        "#Initializing Strategy Class\n",
        "strategy_args = {'batch_size' : 128, 'lr':float(0.1)}\n",
        "strategy = EntropySampling(X_tr, y_tr, X_unlabeled, clf, handler, nclasses, strategy_args)\n",
        "\n",
        "#Initial Training\n",
        "args = {'n_epoch':500, 'lr':float(0.1),'batch_size':128, 'max_accuracy':0.99, 'window_size':20} \n",
        "dt = data_train(X_tr, y_tr, clf, handler, args)\n",
        "\n",
        "#Updating the trained model in strategy class\n",
        "strategy.update_model(clf)\n",
        "\n",
        "# y_pred = strategy.predict(X_test).numpy()\n",
        "acc = np.zeros(n_rounds)\n",
        "acc[0] = dt.get_acc_on_set(X_test, y_test)\n",
        "print('Initial Testing accuracy:', round(acc[0]*100, 2), flush=True)\n",
        "\n",
        "##User Controlled Loop\n",
        "for rd in range(1, n_rounds):\n",
        "    print('-------------------------------------------------')\n",
        "    print('Round', rd) \n",
        "    print('-------------------------------------------------')\n",
        "\n",
        "    #Using select function for getting next set of data points\n",
        "    idx = strategy.select(budget)\n",
        "\n",
        "    #Saving state of model, since labeling new points might take time\n",
        "    strategy.save_state('./state.pkl')\n",
        "\n",
        "    #Adding new points to training set\n",
        "    X_tr = np.concatenate((X_tr, X_unlabeled[idx]), axis=0)\n",
        "    X_unlabeled = np.delete(X_unlabeled, idx, axis = 0)\n",
        "\n",
        "    #Human In Loop, Assuming user adds new labels here\n",
        "    y_tr = np.concatenate((y_tr, y_unlabeled[idx]), axis = 0)\n",
        "    y_unlabeled = np.delete(y_unlabeled, idx, axis = 0)\n",
        "    print('Number of training points -',X_tr.shape[0])\n",
        "\n",
        "    #Reload state and start training\n",
        "    strategy.load_state('./state.pkl')\n",
        "    strategy.update_data(X_tr, y_tr, X_unlabeled)\n",
        "    dt.update_data(X_tr, y_tr)\n",
        "\n",
        "    clf = dt.train()\n",
        "    strategy.update_model(clf)\n",
        "    acc[rd] = dt.get_acc_on_set(X_test, y_test)\n",
        "    print('Testing accuracy:', round(acc[rd]*100, 2), flush=True)\n",
        "    if acc[rd] > 0.98:\n",
        "        print('Testing accuracy reached above 98%, stopping training!')\n",
        "        break\n",
        "\n",
        "print('Training Completed')\n",
        "\n",
        "#Saving accuracies for further analysis\n",
        "with open(os.path.join(base_dir,'entropy.txt'), 'w') as f:\n",
        "    for item in acc:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Testing accuracy: 91.2\n",
            "-------------------------------------------------\n",
            "Round 1\n",
            "-------------------------------------------------\n",
            "Number of training points - 700\n",
            "Training..\n",
            "Epoch: 68 Training accuracy: 0.99\n",
            "Testing accuracy: 96.18\n",
            "-------------------------------------------------\n",
            "Round 2\n",
            "-------------------------------------------------\n",
            "Number of training points - 1050\n",
            "Training..\n",
            "Epoch: 95 Training accuracy: 0.99\n",
            "Testing accuracy: 96.27\n",
            "-------------------------------------------------\n",
            "Round 3\n",
            "-------------------------------------------------\n",
            "Number of training points - 1400\n",
            "Training..\n",
            "Epoch: 204 Training accuracy: 0.992\n",
            "Testing accuracy: 96.88\n",
            "-------------------------------------------------\n",
            "Round 4\n",
            "-------------------------------------------------\n",
            "Number of training points - 1750\n",
            "Training..\n",
            "Epoch: 238 Training accuracy: 0.99\n",
            "Testing accuracy: 96.83\n",
            "-------------------------------------------------\n",
            "Round 5\n",
            "-------------------------------------------------\n",
            "Number of training points - 2100\n",
            "Training..\n",
            "Epoch: 336 Training accuracy: 0.99\n",
            "Testing accuracy: 96.58\n",
            "-------------------------------------------------\n",
            "Round 6\n",
            "-------------------------------------------------\n",
            "Number of training points - 2450\n",
            "Training..\n",
            "Epoch: 398 Training accuracy: 0.99\n",
            "Testing accuracy: 97.46\n",
            "-------------------------------------------------\n",
            "Round 7\n",
            "-------------------------------------------------\n",
            "Number of training points - 2800\n",
            "Training..\n",
            "Epoch: 428 Training accuracy: 0.99\n",
            "Testing accuracy: 97.43\n",
            "-------------------------------------------------\n",
            "Round 8\n",
            "-------------------------------------------------\n",
            "Number of training points - 3150\n",
            "Training..\n",
            "Epoch: 477 Training accuracy: 0.988\n",
            "Testing accuracy: 97.21\n",
            "-------------------------------------------------\n",
            "Round 9\n",
            "-------------------------------------------------\n",
            "Number of training points - 3500\n",
            "Training..\n",
            "Epoch: 491 Training accuracy: 0.981\n",
            "Testing accuracy: 97.83\n",
            "Training Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39teVabl9Kwa"
      },
      "source": [
        "# **BADGE**\n",
        "This method is based on the paper [Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds](https://arxiv.org/abs/1906.03671). Here at each around of selection loss gradients are computed using the hypothesised lables. Then to points to be labled are selected by applying k-means++ on these loss gradients. \n",
        "\n",
        "Here we create a instance of distil.active_learning_strategies.badge.BADGE with same parameters passed to distil.active_learning_strategies.random_sampling.RandomSampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV5_7SLRAboA"
      },
      "source": [
        "**Reinitialize Model & Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUuYC5Dw9LTa"
      },
      "source": [
        "X_unlabeled = deepcopy(x_trn)\n",
        "y_unlabeled = deepcopy(y_trn)\n",
        "X_test = deepcopy(x_tst)\n",
        "y_test = deepcopy(y_tst)\n",
        "\n",
        "nSamps, dim = np.shape(X_unlabeled)\n",
        "\n",
        "np.random.seed(42)\n",
        "start_idxs = np.random.choice(nSamps, size=int(0.01*nSamps), replace=False)\n",
        "\n",
        "X_tr = X_unlabeled[start_idxs]\n",
        "X_unlabeled = np.delete(X_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "y_tr = y_unlabeled[start_idxs]\n",
        "y_unlabeled = np.delete(y_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "n_rounds = 10    ##Number of rounds to run ac\n",
        "budget = int(0.01*x_trn.shape[0]) \n",
        "handler = DataHandler_Points\n",
        "\n",
        "net = TwoLayerNet(data_dims, nclasses, 40)\n",
        "net.apply(init_weights)\n",
        "\n",
        "net.load_state_dict(torch.load(model_directory))\n",
        "clf = net"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwr9CT9F3TFe",
        "outputId": "e3074ef7-2d75-4111-d5f6-a7fad55c9e98"
      },
      "source": [
        "#Initializing Strategy Class\n",
        "strategy_args = {'batch_size' : 128, 'lr':float(0.1)}\n",
        "strategy = BADGE(X_tr, y_tr, X_unlabeled, clf, handler, nclasses, strategy_args)\n",
        "\n",
        "#Initial Training\n",
        "args = {'n_epoch':500, 'lr':float(0.1),'batch_size':128, 'max_accuracy':0.99, 'window_size':20} \n",
        "dt = data_train(X_tr, y_tr, clf, handler, args)\n",
        "\n",
        "#Updating the trained model in strategy class\n",
        "strategy.update_model(clf)\n",
        "\n",
        "# y_pred = strategy.predict(X_test).numpy()\n",
        "acc = np.zeros(n_rounds)\n",
        "acc[0] = dt.get_acc_on_set(X_test, y_test)\n",
        "print('Initial Testing accuracy:', round(acc[0]*100, 2), flush=True)\n",
        "\n",
        "##User Controlled Loop\n",
        "for rd in range(1, n_rounds):\n",
        "    print('-------------------------------------------------')\n",
        "    print('Round', rd) \n",
        "    print('-------------------------------------------------')\n",
        "\n",
        "    #Using select function for getting next set of data points\n",
        "    idx = strategy.select(budget)\n",
        "\n",
        "    #Saving state of model, since labeling new points might take time\n",
        "    strategy.save_state('./state.pkl')\n",
        "\n",
        "    #Adding new points to training set\n",
        "    X_tr = np.concatenate((X_tr, X_unlabeled[idx]), axis=0)\n",
        "    X_unlabeled = np.delete(X_unlabeled, idx, axis = 0)\n",
        "\n",
        "    #Human In Loop, Assuming user adds new labels here\n",
        "    y_tr = np.concatenate((y_tr, y_unlabeled[idx]), axis = 0)\n",
        "    y_unlabeled = np.delete(y_unlabeled, idx, axis = 0)\n",
        "    print('Number of training points -',X_tr.shape[0])\n",
        "\n",
        "    #Reload state and start training\n",
        "    strategy.load_state('./state.pkl')\n",
        "    strategy.update_data(X_tr, y_tr, X_unlabeled)\n",
        "    dt.update_data(X_tr, y_tr)\n",
        "\n",
        "    clf = dt.train()\n",
        "    strategy.update_model(clf)\n",
        "    acc[rd] = dt.get_acc_on_set(X_test, y_test)\n",
        "    print('Testing accuracy:', round(acc[rd]*100, 2), flush=True)\n",
        "    if acc[rd] > 0.98:\n",
        "        print('Testing accuracy reached above 98%, stopping training!')\n",
        "        break\n",
        "\n",
        "print('Training Completed')\n",
        "\n",
        "#Saving accuracies for further analysis\n",
        "with open(os.path.join(base_dir,'badge.txt'), 'w') as f:\n",
        "    for item in acc:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Testing accuracy: 91.2\n",
            "-------------------------------------------------\n",
            "Round 1\n",
            "-------------------------------------------------\n",
            "Number of training points - 700\n",
            "Training..\n",
            "Epoch: 36 Training accuracy: 0.99\n",
            "Testing accuracy: 95.7\n",
            "-------------------------------------------------\n",
            "Round 2\n",
            "-------------------------------------------------\n",
            "Number of training points - 1050\n",
            "Training..\n",
            "Epoch: 73 Training accuracy: 0.99\n",
            "Testing accuracy: 96.8\n",
            "-------------------------------------------------\n",
            "Round 3\n",
            "-------------------------------------------------\n",
            "Number of training points - 1400\n",
            "Training..\n",
            "Epoch: 90 Training accuracy: 0.99\n",
            "Testing accuracy: 97.55\n",
            "-------------------------------------------------\n",
            "Round 4\n",
            "-------------------------------------------------\n",
            "Number of training points - 1750\n",
            "Training..\n",
            "Epoch: 170 Training accuracy: 0.99\n",
            "Testing accuracy: 97.19\n",
            "-------------------------------------------------\n",
            "Round 5\n",
            "-------------------------------------------------\n",
            "Number of training points - 2100\n",
            "Training..\n",
            "Epoch: 239 Training accuracy: 0.99\n",
            "Testing accuracy: 97.41\n",
            "-------------------------------------------------\n",
            "Round 6\n",
            "-------------------------------------------------\n",
            "Number of training points - 2450\n",
            "Training..\n",
            "Epoch: 287 Training accuracy: 0.991\n",
            "Testing accuracy: 97.03\n",
            "-------------------------------------------------\n",
            "Round 7\n",
            "-------------------------------------------------\n",
            "Number of training points - 2800\n",
            "Training..\n",
            "Epoch: 388 Training accuracy: 0.991\n",
            "Testing accuracy: 97.58\n",
            "-------------------------------------------------\n",
            "Round 8\n",
            "-------------------------------------------------\n",
            "Number of training points - 3150\n",
            "Training..\n",
            "Epoch: 381 Training accuracy: 0.99\n",
            "Testing accuracy: 97.79\n",
            "-------------------------------------------------\n",
            "Round 9\n",
            "-------------------------------------------------\n",
            "Number of training points - 3500\n",
            "Training..\n",
            "Epoch: 496 Training accuracy: 0.984\n",
            "Testing accuracy: 97.81\n",
            "Training Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onXfASME-IM7"
      },
      "source": [
        "# **GLISTER**\n",
        "This is implemetation of GLISTER-ACTIVE from the paper [GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning](https://arxiv.org/abs/2012.10630). GLISTER methods tries to solve a bi-level optimisation problem.\n",
        "\\begin{equation*}\n",
        "\\overbrace{\\underset{{S \\subseteq {\\mathcal U}, |S| \\leq k}}{\\operatorname{argmax\\hspace{0.7mm}}} LL_V(\\underbrace{\\underset{\\theta}{\\operatorname{argmax\\hspace{0.7mm}}} LL_T( \\theta, S)}_{inner-level}, {\\mathcal V})}^{outer-level}\n",
        "\\end{equation*}\n",
        "where is $S$ is set of points selected at each round,${\\mathcal V}$ could be a dedicated validation set with labled points or could be union of labeled and unlabeled points with hypothesised labels, $k$ is the budget.\n",
        "To set ${\\mathcal V}$ to be validation set, while calling **GLISTER** class in the toolkit set _valid=TRUE_ and pass validation set otherwise set _valid=False_.\n",
        "\n",
        "Solving this problem directly is almost impossible, therefore we resort to one-step approxiations.We start we $S^0$ as empty set and bulid it as $S^k = S^{k-1} \\cup e$, where $e$ is $\\underset{e}{\\operatorname{argmax\\hspace{0.7mm}}} G_{\\theta}(e | S^k)$. We define,$$G_{\\theta}(e | S^k) = LL_{V}(\\theta^{k}, {\\mathcal V})$$ and update $$\\theta^k \\leftarrow \\theta^{k-1} -  \\eta \\nabla_{\\theta} LL_T(\\hat{\\theta}, e)$$ where $\\hat{\\theta}$ is the parameters of the model at the begining of the selection.\n",
        "To prevent overfitting, we can add regularizer to GLISTER, which can be set by **_typeOf_**. **_typeOf_** can be set to - **'none'**(which is default) for normal GLISTER,**'Rand'** for replacing **_lam_** fraction of points replaced by random points, **'Diversity'** adding diversity set function while computing gain and **'FacLoc'** adding Facility Location set function while computing gain. **_lam_** for both **'Diversity'** and **'FacLoc'** determines the weightage given to them while computing the gain.\n",
        "\n",
        "Here we create a instance of distil.active_learning_strategies.glister.GLISTER( with same parameters passed to distil.active_learning_strategies.random_sampling.RandomSampling, we slight change that, **args** dictionary should have keys ‘batch_size’ and ‘lr’. ‘lr’ should be the learning rate used for training. In addition to those folowing additional parameters may be passed:\n",
        "\n",
        "**valid (boolean)** – Whether validation set is passed or not\n",
        "\n",
        "**X_val (Numpy array, optional)** – Features of the points in the validation set. Mandatory if valid=True.\n",
        "\n",
        "**Y_val (Numpy array, optional)** – Lables of the points in the validation set. Mandatory if valid=True.\n",
        "\n",
        "**loss_criterion (class object, optional)** – The type of loss criterion. Default is torch.nn.CrossEntropyLoss()\n",
        "\n",
        "**typeOf (str, optional)** – Determines the type of regulariser to be used. Default is ‘none’. For random regulariser use ‘Rand’. To use Facility Location set functiom as a regulariser use ‘FacLoc’. To use Diversity set functiom as a regulariser use ‘Diversity’.\n",
        "\n",
        "**lam (float, optional)** – Determines the amount of regularisation to be applied. Mandatory if is not typeOf=’none’ and by default set to None. For random regulariser use values should be between 0 and 1 as it determines fraction of points replaced by random points. For both ‘Diversity’ and ‘FacLoc’ lam determines the weightage given to them while computing the gain.\n",
        "\n",
        "**kernel_batch_size (int, optional)** – For 'Diversity' and 'FacLoc' regualrizer versions, similarity kernel is to be computed, which entails creating a 3d torch tensor of dimenssions $kernel\\_batch\\_size^{2}*(feature\\ dimenssion)$. Again kernel_batch_size should be such that one can exploit the benefits of tensorization while honouring the resourse constraits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Rff450Adx6"
      },
      "source": [
        "**Reinitialize Model & Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8_uPuu4-Iek"
      },
      "source": [
        "X_unlabeled = deepcopy(x_trn)\n",
        "y_unlabeled = deepcopy(y_trn)\n",
        "X_test = deepcopy(x_tst)\n",
        "y_test = deepcopy(y_tst)\n",
        "\n",
        "nSamps, dim = np.shape(X_unlabeled)\n",
        "\n",
        "np.random.seed(42)\n",
        "start_idxs = np.random.choice(nSamps, size=int(0.01*nSamps), replace=False)\n",
        "\n",
        "X_tr = X_unlabeled[start_idxs]\n",
        "X_unlabeled = np.delete(X_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "y_tr = y_unlabeled[start_idxs]\n",
        "y_unlabeled = np.delete(y_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "n_rounds = 10    ##Number of rounds to run ac\n",
        "budget = int(0.01*x_trn.shape[0]) \n",
        "handler = DataHandler_Points\n",
        "\n",
        "net = TwoLayerNet(data_dims, nclasses, 40)\n",
        "net.apply(init_weights)\n",
        "\n",
        "net.load_state_dict(torch.load(model_directory))\n",
        "clf = net"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6-6j7X9-MJr",
        "outputId": "5bb9d9ea-f566-40f0-b35f-2b7be476b32d"
      },
      "source": [
        "#Initializing Strategy Class\n",
        "strategy_args = {'batch_size' : 128, 'lr':float(0.1)}\n",
        "strategy = GLISTER(X_tr, y_tr, X_unlabeled, clf, handler, nclasses, strategy_args,valid=False, typeOf='rand', lam=0.1)\n",
        "\n",
        "#Initial Training\n",
        "args = {'n_epoch':500, 'lr':float(0.1),'batch_size':128, 'max_accuracy':0.99, 'window_size':20} \n",
        "dt = data_train(X_tr, y_tr, clf, handler, args)\n",
        "\n",
        "#Updating the trained model in strategy class\n",
        "strategy.update_model(clf)\n",
        "\n",
        "# y_pred = strategy.predict(X_test).numpy()\n",
        "acc = np.zeros(n_rounds)\n",
        "acc[0] = dt.get_acc_on_set(X_test, y_test)\n",
        "print('Initial Testing accuracy:', round(acc[0]*100, 2), flush=True)\n",
        "\n",
        "##User Controlled Loop\n",
        "for rd in range(1, n_rounds):\n",
        "    print('-------------------------------------------------')\n",
        "    print('Round', rd) \n",
        "    print('-------------------------------------------------')\n",
        "\n",
        "    #Using select function for getting next set of data points\n",
        "    idx = strategy.select(budget)\n",
        "\n",
        "    #Saving state of model, since labeling new points might take time\n",
        "    strategy.save_state('./state.pkl')\n",
        "\n",
        "    #Adding new points to training set\n",
        "    X_tr = np.concatenate((X_tr, X_unlabeled[idx]), axis=0)\n",
        "    X_unlabeled = np.delete(X_unlabeled, idx, axis = 0)\n",
        "\n",
        "    #Human In Loop, Assuming user adds new labels here\n",
        "    y_tr = np.concatenate((y_tr, y_unlabeled[idx]), axis = 0)\n",
        "    y_unlabeled = np.delete(y_unlabeled, idx, axis = 0)\n",
        "    print('Number of training points -',X_tr.shape[0])\n",
        "\n",
        "    #Reload state and start training\n",
        "    strategy.load_state('./state.pkl')\n",
        "    strategy.update_data(X_tr, y_tr, X_unlabeled)\n",
        "    dt.update_data(X_tr, y_tr)\n",
        "\n",
        "    clf = dt.train()\n",
        "    strategy.update_model(clf)\n",
        "    acc[rd] = dt.get_acc_on_set(X_test, y_test)\n",
        "    print('Testing accuracy:', round(acc[rd]*100, 2), flush=True)\n",
        "    if acc[rd] > 0.98:\n",
        "        print('Testing accuracy reached above 98%, stopping training!')\n",
        "        break\n",
        "\n",
        "print('Training Completed')\n",
        "\n",
        "#Saving accuracies for further analysis\n",
        "with open(os.path.join(base_dir,'glister.txt'), 'w') as f:\n",
        "    for item in acc:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Testing accuracy: 91.2\n",
            "-------------------------------------------------\n",
            "Round 1\n",
            "-------------------------------------------------\n",
            "Number of training points - 700\n",
            "Training..\n",
            "Epoch: 52 Training accuracy: 0.991\n",
            "Testing accuracy: 96.26\n",
            "-------------------------------------------------\n",
            "Round 2\n",
            "-------------------------------------------------\n",
            "Number of training points - 1050\n",
            "Training..\n",
            "Epoch: 87 Training accuracy: 0.99\n",
            "Testing accuracy: 96.67\n",
            "-------------------------------------------------\n",
            "Round 3\n",
            "-------------------------------------------------\n",
            "Number of training points - 1400\n",
            "Training..\n",
            "Epoch: 114 Training accuracy: 0.992\n",
            "Testing accuracy: 96.79\n",
            "-------------------------------------------------\n",
            "Round 4\n",
            "-------------------------------------------------\n",
            "Number of training points - 1750\n",
            "Training..\n",
            "Epoch: 218 Training accuracy: 0.991\n",
            "Testing accuracy: 96.77\n",
            "-------------------------------------------------\n",
            "Round 5\n",
            "-------------------------------------------------\n",
            "Number of training points - 2100\n",
            "Training..\n",
            "Epoch: 293 Training accuracy: 0.99\n",
            "Testing accuracy: 97.35\n",
            "-------------------------------------------------\n",
            "Round 6\n",
            "-------------------------------------------------\n",
            "Number of training points - 2450\n",
            "Training..\n",
            "Epoch: 362 Training accuracy: 0.99\n",
            "Testing accuracy: 97.01\n",
            "-------------------------------------------------\n",
            "Round 7\n",
            "-------------------------------------------------\n",
            "Number of training points - 2800\n",
            "Training..\n",
            "Epoch: 486 Training accuracy: 0.989\n",
            "Testing accuracy: 96.97\n",
            "-------------------------------------------------\n",
            "Round 8\n",
            "-------------------------------------------------\n",
            "Number of training points - 3150\n",
            "Training..\n",
            "Epoch: 473 Training accuracy: 0.985\n",
            "Testing accuracy: 96.96\n",
            "-------------------------------------------------\n",
            "Round 9\n",
            "-------------------------------------------------\n",
            "Number of training points - 3500\n",
            "Training..\n",
            "Epoch: 493 Training accuracy: 0.985\n",
            "Testing accuracy: 97.64\n",
            "Training Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGcT3PKrAuQA"
      },
      "source": [
        "# **VISUALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Vlea3j0v-Xvb",
        "outputId": "62d8c818-799d-48ed-e36d-b90d1b38e6a9"
      },
      "source": [
        "#Loading accuracies\n",
        "with open(os.path.join(base_dir,'entropy.txt'), 'r') as f:\n",
        "  acc_ = f.readlines()\n",
        "acc_en = [round(float(x)*100, 2) for x in acc_]\n",
        "with open(os.path.join(base_dir,'badge.txt'), 'r') as f:\n",
        "  acc_ = f.readlines()\n",
        "acc_bd = [round(float(x)*100, 2) for x in acc_]\n",
        "with open(os.path.join(base_dir,'glister.txt'), 'r') as f:\n",
        "  acc_ = f.readlines()\n",
        "acc_gl = [round(float(x)*100, 2) for x in acc_]\n",
        "with open(os.path.join(base_dir,'random.txt'), 'r') as f:\n",
        "  acc_ = f.readlines()\n",
        "acc_rd = [round(float(x)*100, 2) for x in acc_]\n",
        "\n",
        "#Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "budget = 350 \n",
        "n_rounds = 10\n",
        "x_axis = np.array([350+budget*i for i in range(n_rounds)])\n",
        "plt.figure()\n",
        "plt.plot(x_axis, acc_gl, 'b-', label='GLISTER RAND',marker='o')\n",
        "plt.plot(x_axis, acc_en, 'g-', label='UNCERTAINITY',marker='o')\n",
        "plt.plot(x_axis, acc_bd, 'c', label='BADGE',marker='o')\n",
        "plt.plot(x_axis, acc_rd, 'r', label='RANDOM',marker='o')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('No of Images')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('DISTIL_IJCNN1')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'DISTIL_IJCNN1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUVfrHP2fSeyAJNY0eEDAC0hS7a8OGXeyuuLvYFVFYFQvW36rr6rqioOwaUVFQsSCKFCF0CF1pkhAgpEAS0icz7++PMwkpkzAhmUxCzud57jO5d869951M8j3nvuc976tEBIPBYDC0HSyeNsBgMBgMzYsRfoPBYGhjGOE3GAyGNoYRfoPBYGhjGOE3GAyGNoYRfoPBYGhjGOE3GAyGNoYRfkOLRSm1VylVrJQ6qpTKVUolK6X+opSyON7/SCn1QpX2dyulfnO0P6SU+l4pFaKU+kEpVeDYrEqpsir7/1FKnaOUSq9yncVKqT83wM54pZQopbwd+1OUUh9XeV8ppR5QSm1RShUqpdKVUrOVUgOqfA5RSg2tck5PpZRU2V+slCpRSsVUOXaBUmpvlf37lFJrlVKlSqmPXP9NG9oaRvgNLZ3LRSQEiANeBiYC02s2UkqdDbwI3ORo3xf4DEBELhGRYBEJBpKAVyv2ReQvzfAZ/gk8CDwAtAd6A18Bl1Vpcxh4ofap1SgEnqrn/QOOa8w4YUsNbQJvTxtgMLiCiOQB3yilMoCVSql/1GhyOrBCRDY42h8GZjazmbVQSvUCxgMjRGR1lbeSajSdCdyslDpbRJbUcbm3gMeUUq+IyO6ab4rIHMc9hwDRjbfecLJiRvyGVoVDPNOBUTXeWgVcpJR6Vil1hlLKr/mtc8r5QHoN0XdGEfqJZWo9bfYD7wPPNpFthjaKEX5Da+QA2mVSiYj8CowBBgHfATlKqdeVUl4esK8qEcBBF9u+B8QqpS6pp81LwOVKqVMabZmhzWKE39Aa6Yr2iVdDRH4QkcvRncKVwB2Ay5O0biIH6OxKQxEpBZ53bHW1yQLeBp5rEusMbRIj/IZWhVLqdLTwL6urjYjYRWQh8AvQv7lsq4OFQLTD7+4KHwLh6KeXungNOBcY3EjbDG0UI/yGVoFSKlQpNRr4FPhYRDbXeP9KpdSNSql2jvDJocDZwMoTvKW3Usq/yuZzIhcRkZ3Av4FZjrBRX8f1blRKPeGkfTnwDDp6qa5r5gL/AB6velwp5a2U8ge8AC/HfUwAh6EWRvgNLZ15SqmjwD5gMvA6cKeTdkeAe4CdQD7wMfCaiNSMnnGVd4HiKtuHDTy/aqGLB9DumXeAXGA3cDUwr45zZ3H8eYF/ArYax/7usPUJ4BbHz39vkNWGNoEyhVgMhqZFKfU6YBGRhzxti8HgDDPiNxiaEKVUOHARsNbTthgMdWGE32BwAaXU2CppHqpuW6u0GY1246wCPveYsQbDcTCuHoPBYGhjmBG/wWAwtDFaRahXZGSkxMfHe9oMg8FgaFWsW7cuW0Siah5vFcIfHx/P2rVmrsxgMBgaglIq1dlxt7p6lFIPOnKQb1VKPeQ4lqiUWqmUSnHkDh96vOsYDAaDoelwm/ArpfqjF9QMBU4FRiulegKvAs+KSCLwtGPfYDAYDM2EO109fYFVIlIEoJRags4/IkCoo00YOtOiwWAwGJoJdwr/FmCqUioCvXT8UvSiloeAH5VS/4d+4hjp7GSl1DhgHEBsbKwbzTQYDIa2hdtcPSKyHXgFWADMB1LQuUX+CjwsIjHAwzgpo+c4f5qIDBGRIVFRtSalDQaDwXCCuHVyV0Smi8hgETkLnURrB3A7MMfRZDZ6DsBgMBgMVUjanET8m/FYnrUQ/2Y8SZtPNN9gbdwazqmU6iAimUqpWLR/fzhwPzpd7mLgPHQ2RYPBYGgRJB06xOQ9e0grLSXWz4+p3bsztmPH5rVhcxJ3rkjCmvAy+HUgtTSTO1f8F4CxA8Y2+vrujuP/0uHjtwLjRSRXKXUP8E9HnvASHH58g8Fg8DRJhw4x7vffKbLbAUgtLWXc778DNKv4P7huHtYeD4CXvz7g3wlrjwd4cN1HLV/4RaRmQWxEZBmmcpDBYGiBTNqzp1L0Kyiy23lw504KbTasIpSLYLXb9WvFftWfnbxX3oD3S202cmL/DJYa8uzlT06nq5rkc7aKlbsGg8HQ1FjtdrYXFbGxoICUggI2FhSQVlrqtG1OeTn37thR57V8lMJbqdqvFovz447XQC+vyn0Lwr7cvfyRuQnan+H8Rn5N89RhhN9gMJz0HLZa2egQ95SCAjYWFrKtsJAyR3Zif4uF/kFBBFssFNQY8QN09fVl9eDBToXdAiilTtg2EeGr377iiYVPsCNnB6NiR7EpYgh5+NdqG+FVs+jaiWGE32AwnDTYRdhTXFwp7hUj+X1VRvKdfH05NSiIi6KjOTU4mMTgYHoFBOBtsdTy8QMEWiy80qMHXfz8mtze5H3JTPhpAsn7kukb2ZdvbvyG0b1H80lmJnds3Uq55Vjgpbfdzj/7DmiS+xrhNxgMrZJCm40tVcQ9paCAzYWFFNj0qNgLSAgMZFRYGInBwZzq2Dr6+tZ5zYoJXHdH9ezI2cGTC59kzvY5dAruxLTR07jztDvxrvDr/9wRlQTctgc6lEKmH+q/3WFsR2j83G7rKMQyZMgQMdk5DYaTm7rCKEWEA2Vl1XzxKQUF7CwurqxoH+rlVU3cE4ODOSUwEH8vL49+ppocKjjEc0ue47117xHgE8DjIx/nkRGPEOQbVK1dXBykpdU+Py4O9u51/X5KqXUiMqTWcSP8huakJcRIG1oezlws3krR29+fQ1YrOeXllce7+fsfE/mgIBKDg4nz92+Un93dFJQV8PqK13kt+TVKyksYN2gcT5/9NB2Da//tb9kCA+rw6CgFTqYg6qQu4TeuHkOz0VJipA0tjyedhFGWi7CrpIRbO3asFPqBwcGEebce2Sq3lzNjwwyeWfwMGQUZXNP3Gl48/0V6R/Su1TY/H6ZMgbfeAovFucA3VdoyU3rR0Gw4++custuZtGePhywygHtTAxyPI1Yrz+3dW23ytSpWET5ISOC+6GhGhYe3GtEXEb75/RsGvDuAe7+9lx7terD8ruV8cf0XtURfBJKSoE8fePNNuOsueOcdCAysfs3AQJg6tWnsax2/RUOrZ/GRI3X+c6eVlnLTtm1cHRnJJe3bE9JK/rlPBpI2JzFu3jiKrEUApOalMm6eXkzfFCtE6yKrrIw30tN5e/9+jtpsBFgsFDsZ4sa6IZLG3axKX8WEnybwa9qv9I7ozdwb5nJlnyuduqK2bIHx42HpUhgyBL7+GoY6speFhMDkydrXHxurRX9sE30l5j/M4FaOlpczcc8e3j1wAG+lKHcypxRksbDwyBE+zczETykubN+eqyMjuSIigsh6IjBaOy1hvmPywsmVol9BkbWIB354ABHBz8sPXy9f/Lz98PPyw8/bse/k54q23hbvOv3tB0pL+b99+3jvwAGK7Xaui4piUlwc721fwLv5gcdSFADYSrjU+7A7P36TsuvwLiYtnMTsbbPpENSBdy97l7tPuxsfL59abau6dcLC4L334O67oepc9NixTSf0NTGTuwa38fPhw/z5999JKy3l4eho+gcFcd/OnbVipKf16cONHTqwPC+PudnZzMnKIq20FAtwVng4V0dGclVkJLH+tRe0tFbqihef1qdPs4q/5VkLQtNqgEJV6wj8vP2w+HfmaMfLyA0fiSgLHQo30/PoKtrJUfy8/Zi/az5F4SOg+5/BrwOUZsKeD4gr28Xeh/Y2qX1NTVZhFs8vfZ53176Ln5cfj418jEdHPEqIX0ittiLwySfw2GNw6BDccw+8+CJERLjHNhPVY2g28srLmbB7N+8fPEifgABmJCQwMiwMcG2UKyJsKChgbnY2c7Oy2FqkR6SDg4MZExXF1ZGR9A0KqnXf1kB2WRkbCgq4fts2cqtEqlQQ6+dH6ogRzWJLfmk+nf6vE8XlxbXe6xrSlcV3LKa0vJRSWyml5aWU2coqfy61OfarvO/sWKbdl3U+vdnl0wMQYoq3Epu3HK/SQ9WuuzVra512XtbrMgZ1HsRpnU5jUOdBxIbFtogIniJrEW+ufJOXl71MkbWIPw/6M8+c/QydQzo7bb95M9x3n3brnH669uOffrp7bTTCb2gW5ufkcM+OHRwoLeWxmBimxMcT0MhY6h1FRZWdwKqjRwHoExDA1VFRjImMZEhISIsQgqqICPtLS9lQUMD6ggI2HD3K+horSJ2fCH/u0pnro6I4Nzwcb4t74i+2ZG5hzGdj2HV4F94Wb6x2a+V7gT6BTLt8WqN8/FsLC3kxNZVPMzPxtVi4p3NnJsTEEFPHU1v8m/Gk5qXWOh7kE0S3dt3YlrUNu+ino/YB7Ss7gYrXXhG9sKjmiVWx2W3M3DiTpxY9xYGjB7iyz5W8dP5L9I3q67R9Xp526/zrX9qt8/LL2q3jpq+2Gkb4DW4l12rlkd27+TAjg36BgcxISGBYaOjxT2wg+0tL+crRCSzOzcUGRPv5cVVkJFdHRnJWWJjbxLIuRIQ9JSWsd4h7hchnWbWYKqBPYCCDgoMZFBLCacHB/OmX37BFOOkESiwEByoK7DYivL0ZExXF9VFRnNOEncAnmz/hnnn3EOoXyufXfk5afhqTF04mLS+N2LBYpp4/9YRFf/3Ro0xNTWVOdjZBFgt/69qVR6Kj6XScSdqak8xQvQMqshax+dBmNmRsYP3B9aw/uJ7NmZsps5UBEOwbzKkdT2VQ50GVW9/Ivk796yeKiPD9zu+Z+PNEtmZtZXj0cF678DXOjD2zjvY6WuexxyAzE8aN0xO07nLrOMMIv8FtfJudzb07dnCorIyJsbE8HR+PXzOI72GrlW9zcpiTlcWPR45QYrcT4e3N5Y5O4MJ27Rr9tFGTcrud34uLq4n8hoIC8h1pAryVon9QEIOCgznNIfQDg4IIdkQqlZdrMbjjf4fgsd/Bv0okS4kF/q8PIRsjGXjXYexnZ7EpOIdCu41IHx+uiYzkug4dOPsEO7cyWxmP/vgob695m1Gxo/js2s/qdEs0lJV5ebyQmsp3hw8T5uXFA9HRPBgdTYSP68KbtDmpQR2Q1WZlW9Y21h9cX9khpGSkUGgtBMDPy48BHQcwqNMgTuusnwwGdBhAgE9Agz/f2gNrmfDTBBbvXUzP9j15+fyXGdN3TJ1Pmps2abfOr79qd86//62jdpobI/yGJuew1cpDu3bxv0OHGBAUxIcJCQwOqT2h1RwU2mz8ePgwc7OzmZedTZ7NRpDFwiUREVwdGcllERGVMeCuRtOU2u1sKSxkvUPc1x89ysbCQkocE7IBFgunVgi8Q+RPCQpy2unZ7fDZZ/qRf8cO8PEB61mH4M/HcrHwQXeiNnXkiivg22/15J/yt9Hn1sP4XZTFjshsisVOlI8P1zieBM4KD8fLBTdXen46182+jpXpK3l0xKO8dP5LjR4NiwhLcnN5ITWVhbm5RHh783BMDOO7dCG8AYLflNjsNnYd3lX5VFDRIRwpOQKAl/Kib1Tfam6ixE6JhPodezqt2gF1DulMbFgsK9NXEhUYxTNnP8O4wePq/N3l5cEzz8Dbb0N4uHbr3HVX87h1nGGE39CkfJWVxV937iTbamVSbCyT4+Lw9dRfdw3K7HYW5+YyNzubr7KzySgrw0cpzm/Xji6+vszKzKwWMx5osfCvnj3pExRUTeS3FhVVhp+GenlVjuAHBQdzWkgIfRwZHevDboe5c7UYbN0K/fvDc89BUZF+9C+qEkkZGAjTpukQPrsd1q2DefP0lpIC+NnoePlhwq7MJK1rDiXKTocqncCoOjqBhXsWcuOXN1JSXsKHV37Itf2ubdTvV0RYcOQIL6Smsiwvj44+PkyIjeXezp0rn2xaEiJCWl5arc7gYMHByjY92/dkUOdBKFF89ftXlNqqu+Gu6nMVM6+eWa2DqH4P+PhjmDBBu3XuvRdeeKF53TrOMMJvaBKyy8q4f9cuPs3MJDE4mA/79CHRQ6N8V7CLsDI/v3JyeHdJyXHPifLxqeaPHxQSQjd/fywNmEAW0YL9zDNatBMS9Gj/uuuOjf6SklxfoJOerp8C5s2DhQuhFBsB5+YQcU0Wmd1zKLPY6ejjw7VRUVzXoQNnhoWhEF5Z9gp/X/R3EiITmHP9HPpE9nH5M9TELsK8nBxeSE1l7dGjxPj5MTE2lrs6dWpyl1pzkFGQwYaDjjmDjPVsOLiBP3L/cNo2LiyuzrDSTZv0Iqxly/Tiq3fe8YxbxxlG+A2N5ovMTP62cye55eU8FRfHE7Gx+LSQUb4riAheS5bUGbX+Tf/+DAoJoYuv7wlHCYnAjz/C00/DmjXQo4cW/5tvrr44pzEUFmrxnzdPdwYZuTbU8BzaX5NFft8crF52Ovp4E5i7hj92fsgNMafwweXvE+wbfEL3s4nwRVYWU1NT2VxYSHd/fybFxXFrx44t5imvqahrXYNCYX+m+srivDz9Pb/zjnbrvPIK3Hmn59w6zjBJ2gwnTGZZGeN37uSLrCwGBwez8NRTGRB8YiLiSZRSOk7eSUhlnJ8fl0dGNur6v/yihWD5cp0+94MP4LbbtD+/KQkKgiuu0Jt2CXnx7bcdmDejAxu2l8NFG8i8fgnScQAkvsVSH18mpR7k+qgoRoaFufzkYrXb+SQzkxdTU9lRXExCYCD/S0jgxg4dmj1yqrmIDYt1GlYaG3YsO5oI/O9/8Pjj2q3zl79ot0779s1paeMwI35DnYgIn2Vmct/OnRy12ZgSH8+EmJhW/U/vjhWzy5bBU0/B4sXQtat239x9N3gi28Qbi2YycelfsJS1x/7V51g79sT7wizspx/G7m2nk7cvN3TU7qARoaFYlKo12f1sfDylIryclsYfJSWcGhTE3+PiGBMV1SB3V2vkeGGlGzfqaJ1ly2DYMD3aHzzYgwYfB4+4epRSDwL3oEOZ3xeRN5VSnwEVjsZwIFdEEuu7jhH+5iejtJS/7tzJV9nZDA0J4cOEBPq10tWyNWmqHDmrV2vBX7AAOnaESZP0hK0nMkuUlpfy4PwHeW/de5wbfy6fXvspQXSodAl983M5md1z4Nws1LAcxEfoaPElMTSIX47kYlVVdEAABUNDQngqLo7LIiJa3AI5d+IsrPSymLGV0Trt2+tonZbm1nFGXcKPiLhlA/oDW4BAtEvpZ6BnjTb/AJ4+3rUGDx4shubBbrfLfw8elHa//ip+ixfLq6mpYrXZPG1Wi2L9epHRo0VAJDJS5LXXRAoLPWfP3iN7Zci0IcIUZOJPE8Vqs9ZqY7OJrFkj8vTTIgOHW4XzM4TnNwm/LBIW1d5Cf14mdru9WT/Hxx+LxMWJKKVfP/64WW/v1I7YWJF77xXp0EHv//WvIjk5nrHrRADWihNNdduIXyl1HXCxiNzt2H8KKBWRVx37CkgDzhORnfVdy4z4m4f9paX8ZccOvs3JYWRoKDMSEuhTMyl4G2bzZj1RO3cutGunV2Tef79On+spftz1IzfPuZlyezkzr5rJVQlXuXTe/v16YvgvvRY7r8phh443n0NAAG7ffH114rL6wlubi6Sk2naAnqT/7LOW7dZxRrO7epRSfYGvgRFAMbAQ3fvc73j/LOB1Z0Y53h8HjAOIjY0dnJpae8LF0DSICB9lZPDwrl2UifBit27cHx3t0sKgtsBvv+lQzM8/1yL/8MN6c+Sd8wh2sfPC0heYsngKp3Q4hTnXz6FXRK8GX0d9ugI6OUkdkeHHuEUjKC7G5c2xeLnBWCx6wtSZFHl76wIlFovevLyO/dzYfWfvffIJFBTUtiM2FlqjBDV7VI+IbFdKvQIsAAqBFKDqn8ZNwKx6zp8GTAM94neXnW2dfSUljNuxg/mHDzMqLIwZffrQ042j/IYuy/cku3bpxVZJSXpk+sQTepTv6eiNw8WHuWXOLfyw6wduGXgL/7nsP7WKdbtKxFfdybmjduqIiK+6896nDbuW1ep6J1GxFRXp17oqS5WX6zUQdrvuWOz22j9X7FutUFrqWtu63nMm+gD79jXsd9EkNGShR0Nx5v9xxwa8CPzN8bM3cAiIduVc4+Nveux2u0zbv19Cli6VwCVL5F/79onNzT7djzd9LIFTA4UpVG4BLwTIf1P+69b7OrMj7o04UVOUxL0RJx9vqu5M3rtX5O67Rby8RAICRB57TCQzs1lNrJN1B9ZJ/Jvx4vOcj/x79b8b7Yf/+GMRn0syhFnJwsJFwqxk8bkko9n963FxFWP+6ltcXNu0Qz7+WCQwsLoRgYENnviguX38AEqpDiKSqZSKRY/8h4tIrlLqYuBJETnblesYH3/jqRrJ0sXXl3be3mwpKuLc8HA+6NOH7gENT1zVULr8o0u1ZfJV8fPyI8g3iCCfIIJ9gyt/DvJ17Ps42XfSvua5gT6B1dL11heud077sUydquPvldLx2U88AZ2bJo9Zo5m+fjrjvx9PVFAUX1z3BcOihzXJdd05sGyIDS3Vx+8JO4iL01+Is+N797p8GU+Fc/4KRABW4BERWeg4/hGwUkT+48p1jPA3Dmex6wB3duzIBwkJbo/NTs9PZ8riKUzfML3ONhPPmEhhWSEF1gIKywoptBbq/bKCWj9XpOJ1lUCfwMqOYH/+/mq55ysItsVgfTUNu13H4E+eDNHRDf6obqHYWsx939/HjJQZXND9Aj4Z8wlRQVGeNqvJaQkdUIuw49Ah6NTJ+XtKaZ+Ui5iUDW2Y+BUr6lytuteN1Z6OFB/hpWUv869Vb2ETO+Ulfojv0VrtLPlxvNV9Lz4+ejLveK/Ky4pVFVKuCrGqQsoopEwKKJVCyqSQYnsBpfZCSuyFFNsKKLYVUmzVncn/Nv3PubEC7awDuLj/CC5MGM6ImBH0jujdbMU96mLPkT1c+/m1bMjYwORRk3n2nGfxsjRxXhyPK50B0A6dzz/XiX9ycpy3aaIRv0nZ0AZIq6PqU13HXaWsDA4e1KGBVbfUA8WstbxNasyL2H3zYNMtsOg5iFkOl48D3yrP0WWB2H+ayn2bG3JnH/Tav3CXz1BKdxqMXwrhtcMzVFkYQ/t14fvUz5i1YxoA4f7hDOs6jBHRIxgePZxh0cMI93f9no3lux3fccvcWwCYd9M8Rvce3fQ3qenbSE3V+2DEvznJzIS//Q2+/FJneps4UYeS1fQ51TUL3kCM8J/k5FiteCuF1cmTXWwdVZFEdAKqmoJedUtPh6ysGiF4lnK8B/8XOecZbEHpdC64lAvLXyJx1ECib4L774/n0Dzg/MkQlgZ5sbBwKtFHxrLukI7gsFqP/+pKm7peX/5uqtPOR759h/kvjsUudn7P/p0V6StYmb6SFekreHbJs5WJu/pG9q3sCIZHD6dfVL8mH4Hb7DaeXfIszy99nsROiXx5/Zd0b9f9xC9YXg4ZGc6/yNmzdShMVYqK9LLUGTN0zGp4eO3N2fGQkMYtZW2rTx6zZ2vRz8+Hl17SoWPe3tCli9t+H8bVcxKTWVbGBRs3srWgELtVgW+V77rEwkWb+3CZf8dKIa+qBzUXsIDOLd61q7NN2Gn5hnd3TuL3w9sY2nUor1zwCufEn1Pt/JYwcRYfD6mhSbU6n7j8sXU+QeeX5rNm/5rKzmBl+kpyivWjeIhvCEO7Dq3WGUQEupiE3YnQZV99EWPnjGXB7gXcmXgn71z6Tv0Vo44erb933r9f+4xr+oV9fLSw1BecfsYZkJurt7y8umMdK1AKQkNd6yRqHv/5Z704wuOzqs1IdrZ263z+uV4ZNnMmnHJKk97C+PjbGAdKSzl/40ZSS0oIfKE/OXZrrWpPLNT5aSo0oKagR0cf+7lLF+c5aJalLWPizxNJ3pdM74jevHT+S1ydcHWduV08Pahris5HRNh1eFe1p4JNhzZVFgPv1b4XI2JGMLyr7ggGdByAt6XGw7UTQ2wB/jw8JpD3Egp4509vcXf05agDB2oLedXtaO05E8LD6+qhj32pkZF6dB4f71z8nfmSrVY9Kq3aGVT87Mp+fr7zVVr10UCfdqthzhz461/hyBHt0nn8cYcvsmkxwt+G2FdSwtnrN3KguIweHwxg26fO/dJKaQ9AhQY0hK2ZW3ly4ZPM2zGPzsGdmXLOFO467a7aAtcCcUfnU1BWwLoD66p1BpmFmYCOKjq9y+nVngo69h/mVHDLvIAOHfDNzKm9FNbLS8eW1tU7V/TQDUmm15yPYXa77qicdQ633+78nAZGsbR4cnJ0no9Zs2DQIPjoIxgwwG23M8LfBigpgenfFfO490aKvK3w+EAGeIWxb5/+36rJiQym9uXt45nFzzBz40yCfYN54owneHD4gwT6mJw+VRER9ubureYe2pCxgXJbOUP3w8oPdMraWucB6vbbnY/WO3RoumouVfH0YxjU/eQBcN55OknSWWc1q0lNztdf65qMOTm6cMMTTzR9sYYaNHt2zqbczMrdurHZRBYv1itNgxMKhc+SRc37VW55Pk82btRtmmIRYE5Rjjz242Pi97yf+D7vK4/Mf0SyC7Pd86FONux2kVWrpOyRh6Q4upMIiN3Z8lCQfe28PG2tZ3D2RxoQIDJ2rEgn/TuTs88W+eUX/ftsTeTk6M8BIomJIikpzXZr6li563FRd2Uzwl+brVtFnnxSp40FkcC+BRLw3XIJ+2WZrMs9Wqv9iaa8LSwrlJd+fUnCXgoTNUXJ7XNvl71H9jbpZzkpsdtFVq8WmTBBJD5ef0k+PiKXXSYyc6bcPRop8Kku+gU+yM1j8LTlnqOuP9KiIpF//lOkSxf9uzrzTJGffmodHcA33+iOy9tb5JlnREpLm/X2RvhPAg4eFHn9dZFBg/Q35+UlcsklIi9/flQif10mnZYvl60FBU1yL6vNKu+ve1+6/KOLMAUZ/clo2ZSxqUmufdJit4usXSvy+OPHxN7bW+TSS0U+/FDk8OHKpnFvxMlNY5A/whAb+vWmMUjcG3EeM7/FU1ws8vbbItHR+nc7YoTIDz+0zA7g8GGR227Tdg4YoIs4eAAj/K2UggI98Ln4YhGLRX9jgweLvPmmSEaGyNr8fGn/60ezRSAAACAASURBVK/Sdfly+b0JqoHY7XaZu32uJLydIExBhn8wXJbsXdIEn+QkxW4XWbdOZOJEke7dj4n9xReLzJhRZ9UOZwnrAqcG1koYZ3BCSYnIu+8ee9wdOlTk229bTgfw7bf66cTLS+Spp5p9lF8VI/ytiPJykQULRG69VSQoSCqzA06aJLJt27F2K3JzJWzpUolLTpbdRUWNvu/SvUtlxAcjhClIwtsJMnf73GavwtQqsNv1CO7JJ0V69Dj2+HXRRSLTp7tcoul4WUINx6G0VGTatGNPV4MHi3z9tec6gCNHRO64Q9tyyin66c/DGOFv4djtIhs2iDz6qEjnzvqbCQsTuecekSVL9CRuVZYeOSLBS5dKjxUrJLW4uFH33nxos4z+ZLQwBenyjy7y/rr3nZbva9PY7XpSbtIkkZ49j4n9n/4k8sEHItlmottjlJXpDrfiiSsxUWTOnNr/NO7khx9EunbVj+WTJumnkhaAEf4Wyr59Ii+/LNK/v1TO/115pcgXX2iXpjN+PnxYApcskYRVq2R/I/7AUnNT5fa5t4uaoiTspTB5+deXpbDMg8VjWxp2u8jGjSKTJ4v06nVM7C+8UI80s7I8baGhKlaryMyZx76rgQNFZs92bweQm6tD6kCkXz89od+CMMLvIZwFKuTlaffvuefq4yAycqTIv/99/IHj99nZ4rd4sfRfvVoyGuA7rOpWiH49Wi79+FLxe95P/J73kwkLJkhOUSuqIO1O7HaRTZtE/v53kT599JdjsYicf77Ie++1nIoshrqxWvU/WsX316+fyKxZ2ofalPz4o55otlj0HE8jn7zdgRF+D+AsNNnLS8/9gfYYPPusyK5drl3vq6ws8V28WE5bs0ayGij6NScSmYKcNeMsSctNO8FP14px1htv2SLy9NMiCQnHxP6880T+8x+RQ4c8bbHhRCgv14Lfr5/+ThMS9HdtbaQbMy9P+2ArrrlyZdPY6wbqEn6zcteN1JUQLPiPsfz8s86+6moNlNmZmdy8fTuDgoOZP3Ag7Xx8KC0vJac4h6zCLLKLsskuyiarqPbPv6b+6rT4SFxYHHsf2tukn7nF4yxFgVK6X7ZY4Oyz4frr4eqroWNHz9lpaDrsdp3u+LnnYMsW6NUL/v53uPnmhufH+flnXaknPR0efRSefVYXZG6hmJQNHkANTHKaAph505BN1ZfE28VObkluNRGvEO9fS/z4wetUwssO0D19GkcK95NVmMXRMicJuhy0D2hPZGAkkYGRJO9Ldm4fCvszJ1EeFFeoKzVAu3awbVvdlY8MrR+7Hb76SncAGzdC9+46VcWttx4/dcLRozqR2n/+A7176xw7bixi1FQY4fcA3hPisQU7KfphDebqgX86Ju6FWeQU51Rmd6xGp0ug92P4FfxGQsb/6BQQVinoUYFRlT9HBkYSFaT32we0r5YsLf7NeFLzatvRJkf8FovzDJEnWzIwQ92IwDff6A5g/Xo9GJg0SSeK8/Wt3X7RIrjrLj1geOQReP75Fj3Kr4oRfg+gnrUAzn+/p0SdUl20q4h4hYDPL/Jl8r5sLmrXjrn9+xNwggm66iswPnbASZrrvCbZ2fDAAzorojNO1vS/hroRge+/1+6aNWt0gronn9Si/swzOmldUJCuQ9Czpx7ln3GGp61uEKb0ogeIC4utc6S95W9b6j33zX37mLxvN5dHRPB5v374NyIrY4W4T144mbS8NGLDYpl6/tS2I/pffKELXhw5AmPGwPz5bitpZ2hFKAWXXQaXXgo//qg7gL/+9dicD2jR9/bWTwStTPTrw4z43UjS5iRunX034nWstJ0rI+1X0tJ4Ys8eromM5JN+/fBtTDm7tkxmJtx3ny5tVzX3eUtIQ2xoeYjoOZ7MzNrvtdInwrpG/G5VFKXUg0qpLUqprUqph6ocv18p9Zvj+KvutMGTXNNrLPL75YCeSI0Li6tX9EWEZ/fu5Yk9e7i5Qwc+NaJ/YojAZ5/pMnZff62FfeXKYwUvxo7V/8R2u341om8APdLPynL+Xlpa89riZtzm6lFK9QfuAYYCZcB8pdS3QAxwJXCqiJQqpTq4ywZPs24d4FNIrP8ppE6s37UjIkz+4w9eSkvjjk6d+KBPH7xcjfU0HCMjQxeunjtXx8vOmNHkdUwNJzGxsc6jvmJjm98WN+LO4WRfYJWIFIlIObAEGAP8FXhZREoBRMTJc9XJwfJkO0Sv4Ozu9fsGRYRHd+/mpbQ07u3cmelG9BuOiHbhnHKKnrB79VVYvtyIvqFhTJ2q53yqchLOAblT+LcAo5RSEUqpQOBS9Gi/t+P4KqXUEqXU6c5OVkqNU0qtVUqtzarr8auFs2D9dgjI5fxeI+tsYxdh/M6dvJGezoNdu/Ju795YjOg3jAMH4Mor4ZZboE8fSEmBCRPcUrzacJIzdqyuNxwXp10/cXHuqT/sYdz2nyEi25VSrwALgEIgBbA57tkeGA6cDnyulOouNWaZRWQaMA305K677HQXIrDmUDIkwMgY58JvE+He339nekYGj8fE8HL37igj+q4jAjNnwsMPQ2kpvP66Dtl0R11aQ9th7NiTTuhr4taZQxGZLiKDReQs4AiwA0gH5jhSSawG7ECkO+3wBHv3Qn5oMsEqip7te9Z6v9xu547ffmN6RgZPx8UZ0W8o+/bpULw779STths36g7AiL7BcFzc+iyslOogIplKqVi0f384WujPBRYppXoDvkC2O+3wBCtWALHLGdJxZC1Bt9rtjN2+ndlZWUzt1o1JcXGeMbI1IgLTp+s8KeXl8NZbOkbfRD8ZDC7jbifol0qpCMAKjBeRXKXUDGCGUmoLOtrn9ppunpOBX1ZmQcROLur352rHS+12bti6la9zcvhHjx48EhPjIQtbIampcM898NNPcM45ugPo3t3TVhkMrQ63Cr+IjHJyrAy4xZ33bQks2rUCIuDMuGP+/WKbjWu2buWHw4d5u1cvxnft6kELWxF2u55gmzBB7//733DvvWaUbzCcICbswQ0UFsIftuVYxIdd3nHcsmIFaaWl+ClFiQjTevfmni5dPG1m6+CPP3Qa3EWL4IIL4IMPdKSFwWA4YcyQyQ2sWQPSNZkOsXcxftcfpJaWIkCJCL5KEWgmII+P3Q5vv60nbteuhfffhwULjOgbDE2AEX438GtyGXRdQ0H8FRTVSPVbJsLkPXs8ZFkrYdcuOPdcuP9+GDUKtm6FP//Z9ao1BoOhXozwu4EFmzaAdymFFuc5u9NKS50eb/PYbPDmmzBwoA7P/PBDvQrXTIAbDE2K8fE3MSKwIWc5AF18fdhfVl6rTayfX3Ob1fL5/Xdd7CI5GUaP1pWOzOS3weAWjjviV0oZh3QD2LULCtsnE+nVjVd69MKnhnsi0GJhqglBPIbNBq+9BomJsH07/O9/ujqSEX2DwW244urZqZR6TSnVz+3WnAQkJwvELGdYl5GM7diRXv7++CiFAuL8/JjWpw9j23IR76QkXerOYoEuXXRunccfh4sv1jVvb7nF+PINBjfjiqvnVOBG4AOllAWYAXwqIvlutayV8uPqvdAhg0v6n0Gp3c6e0lLGd+3KGz1rp21ocyQlwbhxx6pfHTyoX8ePh3/9ywi+wdBMHHfELyJHReR9ERkJTASeAQ4qpWYqpYya1WBZajIAZ8aOZFV+PiV2O+eEh3vYKg9SUqKjcr7+WlfDqlrysIJvvzWibzA0I8cd8Tt8/JcBdwLxwD+AJGAU8D06zbIByM+HfSTjKyH079CfqWn7UMBZYWGeNs29FBbC7t16gqPmlp5+rH5pXZxk1Y0MhpaOK66encAi4DURSa5y/Aul1FnuMat1sno1ELOc/uHD8bJ4sSg3l8TgYNr5+HjatMaTn19b3Hfu1K8VLpsKOnSAnj11LH7Pnse2MWN0R1CTk6y6kcHQ0nFF+AeKSIGzN0TkgSa2p1WzKDkfOmzmwoSnKLHZWJGX13Ly8bhSYDw3t7aoV2w1C1B37qzF/OKLq4t7jx5Q1xPOyy9X9/HDSVndyGBo6bgi/O8opR4UkVwApVQ74B8icpd7TWt9LNi6GvrZOa/XSFbm51Mq0jL8+zUnVVNTdcz8nDkQEHBM3HNyqp8XHa3F/IoroFevY+LevTsEBzfcjoqO5ngdkMFgcCuujvhzK3ZE5IhS6jQ32tQqsdthS95yEMXw6OG8fiAHCzCqJfj3J0+uPalaVqaFPz5ei/l111UfuXfvrjuFpqYNVDcyGFo6rgi/RSnVTkSOACil2rt4Xpvit9+gJCqZaN8BhPqFsih3N6cFBxPeEvz7dU2eKqWzXxoMhjaFKwL+D2CFUmo2oIBrAeOUrcHyZBtEr+TMuJspttlYmZ/PA9HRnjVKRK+KrSuqxkyqGgxtElfi+P8LXAMcAjKAMSLyP3cb1tr4Yd028M/nkv4jWZGfT5mn/fslJXDHHTBxIgwbVtttYyZVDYY2i0vZOUVkK/A58A1Q4Kiha6jCinSdmO3M2DNYnJvrWf9+Rgacdx7897/w3HO6APD77+tc9krp12nTjK/dYGijuLKA6wq0u6cLkAnEAduBU9xrWuvhyBHI8EkmmI50C+/Gor0pDA4JIdTbA1MhGzbAlVdCdjbMng3XXquPm0lVg8HgwJUR//PAcGCHiHQDzgdWutWqVsaqVUBMMokRIym221mVn8+5nnDzfPklnHmm9ukvX35M9A0Gg6EKrgi/VURy0NE9FhFZBAxx5eJKqQeVUluUUluVUg85jk1RSu1XSqU4tksbYX+LYEHyIWi/m0v6n0FyXh7W5vbvi8Dzz2uhHzhQ1348zUTcGgwG57jii8hVSgUDS4EkpVQmUHi8k5RS/YF7gKFAGTBfKfWt4+03ROT/TtDmFsfCHcnQF87tMZLvcnPxAs5sLv9+UZFejPXZZ3Drrdp37+/fPPc2GAytEldG/FcCRcDDwHxgN3C5C+f1BVaJSJGIlANLgDEnamhLxWaD7QXJeIkfgzoPYlFuLkNCQghpDv/+/v1w1lnw+ec6HcLMmUb0DQbDcalX+B2ZOb8VEbuIlIvITBF5y+H6OR5bgFFKqQilVCBwKVBRPPU+pdQmpdQMRwqIVsvWrWDttJweAUMoV96sPnqUc9s1w0daswZOP12XLPzqKx22aVIbGwwGF6hX+EXEBtiVUg32W4jIduAVYAH6SSEFsAHvAj2AROAgOmKoFkqpcUqptUqptVlZWQ29fbOxNLkEOq/j7O4jWZ6XR3lz+PdnzdIjfT8/XaP2iivcez+DwXBS4YqrpwDYrJSarpR6q2Jz5eIiMl1EBovIWcARdGTQIRGxiYgdeB89B+Ds3GkiMkREhkRFRbn6eZqd79avB+8yLuk/kkW5uXgrxRmhoe65md0OTz0FN9+sR/urV8OAAe65l8FgOGlxxRE9x7E1GKVUBxHJdCz4GgMMV0p1FpGKBO5Xo11CrZa1h5ZDVzgjdiSv/p7O0JAQgt3h3y8ogNtug7lz4e674d//Bl/fpr+PwWA46TmuQonIzEZc/0ulVARgBcaLSK5S6l9KqURAgL3AvY24vkfJyoLsgGQiVE8C/NqzJn8bE92R/yY1VS/K2rwZ3nwTHnjA+PMNBsMJ48rK3T/QIl0NEel+vHNFZJSTY7e6bF0LZ8UKgZhkhnS8mOV5edig6RduJSfD1VdDaSl8/z1cdFHTXt9gMLQ5XPFJVF2s5Q9cB7R3jzmti+9X7obgTC4bqP37Pkoxsinj9z/6CO69V2fRnDcPEhKa7toGg6HN4kp2zpwq234ReRNdfL3Ns3i3LkF8bg+dmG1YaCiBXl6Nv7DNBhMmwJ136hQMq1YZ0TcYDE2GK66eQVV2LegngDZfiKW8HHaXJeNrDyW6XW/WbUvmybi4xl84P19H7Xz3Hfztb9qn3xKKuRgMhpMGVwuxVFAO/AFc7x5zWg+bNkF552QGBo8gOf9o0/j39+yByy/Xi7LeeUcLv8FgMDQxrkT1nNschrQ2fl6WCx22cEGf61iUm4uvUoxoTPz+4sU6yZrdDgsW6Hz6BoPB4AaO6+NXSr2olAqvst9OKfWCe81q+fyweRUo4ZJTRrI4N5fhoaEEnKh/f9o0uPBCiIrSi7KM6BsMBjfiysrdS0Qkt2LHUXS91adSbiwbspNBLCR0Gsz6o0dPLE1DebmOyb/3XrjgAli5Enr2bHpjDQaDoQquCL+XUsqvYkcpFQD41dP+pCcjA/JCl9PV61RSisuxcwL+/SNH4NJL4V//gkcegW+/BU+VajQYDG0KVyZ3k4CFSqkPHft3Ao1ZzdvqWZZcDl1XMbzr7SzKzcVPKYY3xL+/Y4eexP3jD5g+XefTNxgMhmbClcndV5RSG4ELHIeeF5Ef3WtWy2beqi0QWMDliSN5KzeXEWFh+Lvq3//pJ7j+evD2hoULYVStxc0Gg8HgVlyZ3O0GLBaRx0TkMWCpUire3Ya1ZJalLgcgMXYYGwoK6vfvJyVBfDxYLNC+vU65EB2t8+kb0TcYDB7AFR//bMBeZd/mONYmKSuDvfZkguxd2CuhCPX495OSYNw4nWRNRPv1LRZ46CHdGRgMBoMHcEX4vUWkrGLH8XObzQe8YQPYuyQzIHwki/Py8LdYGFaXf3/yZF0Ttyo2my6MbjAYDB7CFeHPUkpVlnhSSl0JZLvPpJbN/OUHoN1eLuqn4/dHhobiZ6nj15iW1rDjBoPB0Ay4Ivx/ASYppdKUUvuAicA495rVcvlxm07MdkbfkWwsKKg/jLOu3PzuyNlvMBgMLuJKds7dIjIc6Af0FZGRtOG0zJtzk/Gy+5PrF4tA/RO7U6dqn35VAgP1cYPBYPAQroz4K4gFJiqldqILprc59u2DgnbJxPuezrL8AgIsFobWF78/cqTOvRMeritmxcXp9Axjxzaf0QaDwVCDeuP4HWGbNzk2KxAHDBGRve42rCWyZHkxdF7PmXGPsig3lzPCwvCty78P8Mkn+jUlRYu+wWAwtADqVC2l1ArgO3TncI2IDAaOtlXRB/hm7VrwsnJu4hlsLiys378vosM5R40yom8wGFoU9bl6DgEhQEcgynGsVu3dtsSK/Xpi1x7eFziOfz8lBbZvN24dg8HQ4qhT+EXkKmAAsA6Y4ii63k4pNbS5jGtJlJTAfsty2tt7s77YTqDFwukhIXWfkJSkK2ddd13zGWkwGAwuUO/krojkiciHIvInYBjwFPCGI6zzuCilHlRKbVFKbVVKPVTjvUeVUqKUijxh65uRtWsFiU7mtMgzWHTkCGeGheFTl3/fZoNZs+CSS3SaBoPBYGhBuBzVIyKZIvK2iJwBnHm89kqp/sA9wFDgVGC0Uqqn470Y4E9Aq1nJ9M3ynRCYw6gBo9haVFS/f3/JEjhwwLh5DAZDi6Qh4ZyViEiqC836AqtEpEhEyoElwBjHe28Aj9OK5gwW7tCJ2UKjTwWO499PSoKQEJ162WAwGFoYJyT8LrIFGKWUilBKBaKrdsU4Uj7sF5GN9Z2slBqnlFqrlFqblZXlRjOPjwhsL0zG19aOnfYggr28GFyXf7+kBL74AsaMgYCA5jXUYDAYXMCVtMxnuHKsJiKyHXgFWADMB1LQlbsmAU+7cP40ERkiIkOioqKO19yt7N0LxRHJ9AoYweLcvPr9+999B/n5xs1jMBhaLK6M+P/l4rFaiMh0ERksImcBR4CtQDdgo1JqLxANrFdKdXLRXo/w07LD0GEbQ3uezfbj+feTkqBTJ1Mw3WAwtFjqXLmrlBoBjASilFKPVHkrFHCp3JRSqoOIZCqlYtH+/eEi8s8q7+9FrwRu0dk+v9mwEsKgS8JQyKnHv3/kiB7x/+1v4GpFLoPBYGhm6kvZ4AsEO9pUdWjnA9e6eP0vlVIR6HQP40Uk94Ss9DDrDiWjQr3I8I4ixOswg4KDnTf88ktdqcW4eQwGQwumTuEXkSXAEqXURxVRPEopCxAsIvmuXFxE6q0tKCLxDbDVIxQWQoZPMp1JZFl+AaPCwvCuy7+flAS9e8Pgwc1rpMFgMDQAV3z8LymlQpVSQehInW1KqQlutqvFsGKVFbquYkDX8/i9uLhu//6+fbB4sR7tK9WsNhoMBkNDcEX4+zlG+FcBP6AnZ291q1UtiK9WbALfIuL66UCmOv37s2bp15tvbibLDAaD4cRwRfh9lFI+aOH/RkSstKKFV41l8R6dmK0wNIYwLy9Oqyt+PykJhg2Dnj2b0TqDwWBoOK4I/3vAXiAIWKqUikNP8J70iMDOkuUElkezpsjKWeHheDlz42zZAps2mUldg8HQKnCl9OJbItJVRC4VTSpwbjPY5nF27YKyjsn0bPcndhYX1+3mSUrS4Zs33NC8BhoMBsMJ4MrK3Y5KqelKqR8c+/2A291uWQtg3tJ9ELaPuD5nAzif2LXbdaWtCy+EDh2a2UKDwWBoOK64ej4CfgS6OPZ3AA/V2fok4vvN2r+vOncn3Nubgc7i95cvh7Q04+YxGAythvpKL1bE+EeKyOeAHcCRadPWDLZ5nJScZLxsgWwt8+bssDDn/v2kJAgMhKuuan4DDQaD4QSob8S/2vFa6Fh9KwBKqeFAnrsN8zT5+ZATkEznwAvYXVLi3L9fVgazZ8OVV0Jdq3kNBoOhhVFfyoaK4e0jwDdAD6XUcnT9XVdTNrRalqwohM4b6NrtdtKBc9u1q91o/nw4fNi4eQwGQ6uiPuGvmpxtLvA9ujMoBS4ANrnZNo8yZ+UasNgIiEmgvd2bAUFBtRslJUFkJPzpT81voMFgMJwg9bl6vNBJ2kLQMfzejmOBVE/adlKyPE1P7P6hAjk7PBxLTf9+fj588w1cf70uqm4wGAythPpG/AdF5Llms6QFYbfDH+XJhHqdQWppGY/EOPHvz52rq20ZN4/BYGhl1Dfib7OZxrZtt1PeOZlOXS8F6ojfT0qCbt1gxIhmts5gMBgaR33Cf36zWdHCmPvr7xBwhKCYAUR4e3NKTf9+RgYsXKgTsplMnAaDoZVRp/CLyOHmNKQlsWCb9u8fCgjnHGf+/U8/1f4g4+YxGAytEFdW7rY5Nuctx9urLwesNufx+0lJcNpp0Ldv8xtnMBgMjcQIfw2OHIG80GQio64EnMTv79gBa9ea0b7BYGi1GOGvwY+/ZkPk7wR3HUSUjw/9AgOrN0hK0n79G2/0jIEGg8HQSIzw1+CrtSsAyAuN4pzwcFRV/76IFv5zz4WuXT1kocFgMDSO+uL42ySrDiRDjxiy7E7KLK5eDbt3w6RJnjHOYGgmrFYr6enplJSUeNoUgwv4+/sTHR2Nj4uLSd0q/EqpB4F70GsC3heRN5VSzwNXorN9ZgJ3iMgBd9rhKjYbpJFMSNgVHMVJ/H5SEvj5wTXXeMQ+g6G5SE9PJyQkhPj4+OpPvYYWh4iQk5NDeno63bp1c+kct7l6lFL90aI/FDgVGK2U6gm8JiIDRSQR+BZ42l02NJSUzWXYO60muNMwOvr4kFDVv19eDp99BqNHQ1iY54w0GJqBkpISIiIijOi3ApRSRERENOjpzJ0+/r7AKhEpcuTwXwKMEZGq9XqDaEGF22f/mgI+JRS361Lbv//zz5CZaaJ5DG0GI/qth4Z+V+4U/i3AKKVUhFIqELgUiAFQSk1VSu0DxlLHiF8pNU4ptVYptTYrK8uNZh5j4Y5kCOhKrvKqHcaZlATh4XDppc1ii8FgMLgLtwm/iGwHXgEWAPOBFByVu0RksojEAEnAfXWcP01EhojIkKioKHeZWY3fCpPxCdaZKqpN7BYW6qRs112nffwGg6EaSUkQHw8Wi35NSmr8NQ8dOsTNN99M9+7dGTx4MCNGjGDu3LkALF68mNGjR9c655xzzmHt2rUAzJgxgwEDBjBw4ED69+/P119/zfjx40lMTKRfv34EBASQmJhIYmIiX3zxBXfccQfdunWrPDZy5EgAPvroI6KiokhMTCQhIYE33njDqb3Ha5eSkoJSivnz51c7rpTi0Ucfrdz/v//7P6ZMmQLAlClT6Nq1K4mJifTq1YsxY8awbdu2E/uFVsGt4ZwiMl1EBovIWcARdL3eqiQBLWKmNDNTKGi3nKDIUXT29aV3QMCxN7/5Rou/cfMYDLVISoJx4yA1VUc8p6bq/caIv4hw1VVXcdZZZ7Fnzx7WrVvHp59+Snp6ukvnp6enM3XqVJYtW8amTZtYuXIlAwcO5J133iElJYXvv/+eHj16kJKSQkpKCtdeq2tLvfbaa5XHkpOTK693ww03kJKSwvLly5k6dSr79u1zet/62s2aNYszzzyTWbNmVTvHz8+POXPmkJ2d7fSaDz/8MCkpKezcuZMbbriB8847j8Z6Qdwd1dNBRDKVUrHAGGC4UqqXiOx0NLkS+M2dNrjKvKVpEHqAsog4Lqnp309KgpgYGDXKcwYaDB7ioYcgJaXu91euhNLS6seKiuDuu+H9952fk5gIb75Z9zV/+eUXfH19+ctf/lJ5LC4ujvvvv98lmzMzMwkJCSHYURI1ODi48ufGEBERQc+ePTl48CAxMTEutxMRZs+ezU8//cSoUaMoKSnB398fAG9vb8aNG8cbb7zB1KlT673/DTfcwHfffccnn3zCgw8+eMKfw90LuL5USm0D5gHjRSQXeFkptUUptQn4E3Di1jch32xIhoAYirx8qodxZmfDjz/CTTfp51iDwVCNmqJ/vOOusHXrVgYNGnTC55966ql07NiRbt26ceeddzJv3jyXzpswYUKlq2eskyf8tLQ0SkpKGDhwYL3XqdkuOTmZbt260aNHD8455xy+++67au3Hjx9PUlISeXnHL2c+aNAgfvutceNlt474RaTWEFlEWoRrpyZrM5ejYoYh1PDvf/65DuU0bh5DG6W+kTlon35qau3jcXGweHHT2DB+/HiWLVuGr68va9asOW57Ly8v5s+fz5o1a1i4cCEPP/ww69atq/Sd18Vrr71WipianAAAHHFJREFU6fapymeffcbSpUv57bffePvttytH6662mzVrFjc60rzceOON/Pe//+WaKuuBQkNDue2223jrrbcIqOpmdoJI4wMhzRAWsFrhoE8y/uHn0NXXl55Vf/FJSdC/PxynhzcY2ipTp0LNlFaBgfr4iXLKKaewfv36yv133nmHhQsXNsi3rZRi6NChPPnkk3z66ad8+eWXJ2zPDTfcwKZNm0hOTuaJJ54gIyPD5XY2m40vv/yS5557jvj4eO6//37mz5/P0aNHq5370EMPMX36dAoLC+u1ZcOGDfRtZGZgI/zAyvUFSNRG7BE9q8fv//EHJCeb0b7BUA9jx8K0aXqEr5R+nTatcf825513HiUlJbz77ruVx4qKilw+/8CBA9U6jpSUFOLi4k7cIAdDhgzh1ltv5Z///KfL7RYuXMjAgQPZt28fe/fuJTU1lWuuuaYyQqmC9u3bc/311zN9+vQ6r/vll1+yYMECbrrppkZ9DpOrB/g8eRUER1Pq41c9fv+TT/RrI3/JBsPJztixTTs+Ukrx1Vdf8fDDD/Pqq68SFRVFUFAQr7zySmWbhQsXEh0dXbk/e/bsyp+tViuPPfYYBw4cwN/fn6ioKP7zn/8c974TJkzghRdeqNxfvXp1rTYTJ05k0KBBTJo0iZCQkDqvVdEuIyODq6++utp711xzDe+++y633XZbteOPPvoob7/9drVjb7zxBh9//DGFhYX079+fX375hcaGuKum8Be5myFDhkhFbK47GHj/82wesA56P8SuYcPoERCg49JOOQUiI2HpUrfd22BoiWzfvr3R7gRD8+LsO1NKrRORITXbGlcPsKskGe/Qs4jx86N7xaRNSgps327cPAaD4aSjzQv//gN2iiNXQES/6v79jz8GHx+9WtdgMBhOItq88M9evA3at6Pcx/9Y/L7NBrNmwSWXQPv2njXQYDAYmpg2L/zfb06G8ESgSvz+4sVw8KBx8xgMhpOSNi/8Gw8no0KHEefnR7eK+P2kJAgJgcsv96xxBoPB4AbatPCXlUGmfzKq3anHwjhLSv6/vbMPj6q69v9nJcaQCAVJgNJgMrzJhfAyCVGaX4Fb4UYFGlFERXMRBEu1eEt6S38/kdbShydyVYQIQi19pKLEhBeLKFdQARGKgSsBhEBAQBLl5UIQMCCCkOzfH+dkmAkzeSEZhsmsz/PMM+esvc85a8+erOxZ5+zvhrffhmHDoIYZdIqiKMFISAf+NZuOwy2XqLgx6nKaZ8UKKCvTNI+i1IGcnTk4sh2E/TkMR7aDnJ3102UuLi6me/fuHrYpU6Ywffp0Ro8eTVxcHBdsMaATJ07gcDhc9b744gsGDx5M586dSU5O5sEHH+TYsWOsW7eO5s2bu7R4nE4nq1evBiyJB6fTSffu3UlPT+f06dP06dMHp9NJfHy8S27Z6XRSXFzMpUuXaNWqFU8//bSHj+6y0A6Hw0OWoVL6GSwJ56eeeoqsrCzXeSt9cDqdvPzyy6SmprrkGcrLy0lKSvJQDK0PIT2Ba+mmfGiZBLjl93Ny4Mc/hgEDAuiZogQPOTtzGPfeOM5dtGbWlnxbwrj3xgGQ0cM/A6jw8HDmz5/Pk08+6WE/f/48Q4YMYcaMGaTbqdp169a5pB769evHihUrrjhfVFQU220J0lGjRjFnzhw2b94MWEF6y5YtHhOrVq5cya233sqSJUuYNm2azxWwCgoK2L17N926dfNaPnnyZCZPngxYCqLb3WRQ8/Pzee2113j88ceZPXs2KSkprjUC6ktIB/6NX28ERxKOyEgSmjSBU6fg/ffh17+G8PBAu6co1wWZqzLZ/r++dZk3HdrEhXJPKc5zF88xdvlY/lbgXZfZ+WMn2XfXoP5WnU+ZmcycOZNf/vKXHva33nqL1NRUV9AHaxQO1j+A2pCamsqOHTuqrZObm8uECRP4y1/+Qn5+vs+A/Lvf/Y6srCxyrmJxgpkzZ9K3b19SU1N55ZVXvM4ivlpCOtXz5aV8pEUyAyrz+0uXWol/TfMoSq2pGvRrsjcE8fHx9O3blzfffNPDXlhYSO/evX0et2HDBo9Uz4EDBzzKy8vLWbNmDffcc4/Pc5w/f57Vq1eTnp7Oww8/fMXCKu48+OCDbN26lf3799eyZZdp27YtmZmZpKam8oc//IGWDfhoeciO+PcXX+Ci4wTcGO2Z5rn1Vqjmi6MooUZNI3NHtoOSb6/UZU5onsC60euu6pq+Uifu9kmTJjF06FCGDBlS6/P6SvV8//33OJ1ODh8+TNeuXUlLS/N5jhUrVnDHHXcQFRXF/fffz9SpU8nOzibcS5YgPDyc3//+90ybNo1BgwbV2s9Kxo8fz9NPP+26N9BQhOyIP2/dVohJBOz8/tdfwyefWKP9Oq5YryihTNbALKIjPHWZoyOiyRp49brMMTExnDp1ysN28uRJYmNjXfudO3fG6XSyePFily0xMZGCgoI6X68yx19SUoIxhjlz5vism5uby+rVq3E4HPTu3ZtvvvmGtWvX+qw/cuRI1q9f73O5xuoICwvz+U+wPoRs4P9wjzVxK+HGCG5p0sSaqQvwyCOBdUxRgoyMHhnMS59HQvMEBCGheQLz0ufV68Zu06ZNadu2rSugnjx5klWrVtG3b1+PepMnT2b69Omu/UceeYRPP/3UY4Wr9evXU1hYWKvrRkdHM2vWLF566SUuXbp0RXlZWRkbNmzgq6++ori4mOLiYubMmVNtuiciIoLf/va3PhdpDwQhG/h3luVD8yTSYuwRRE4O9OkDnToF1jFFCUIyemRQnFlMxZ8qKM4sbpCned544w2mTp2K0+lkwIAB/OlPf6Jjx44edRITEz2WaIyKimLFihXMnj2bzp07061bN+bOneuSMa6a41+6dOkV101KSqJnz55eg/myZcsYMGAAkZGRLtvQoUN57733XI+XemPs2LFe/5EEipCUZT53znDTS6nQ779Y2LUrGaWl0KMHzJoFtVzMWVEaMyrLHHyoLHMNrNh4EH4SD9j5/Zwc6/HNhx4KsGeKoij+JyQD/7ItVn6/XXgYcRER1kpbaWnQunWgXVMURfE7fg38IjJBRApFZJeIZNq2F0Vkj4jsEJFlItLCnz54Y9ORfPhRLwa1ag0bN8JXX+mz+4qihAx+C/wi0h34JXA70Av4hYh0Aj4CuhtjegJfAJP85YM3jIGvW5RAxE2WMFtODkRHw733Xks3FEVRAoY/R/xdgc3GmHPGmEvAJ8AwY8yH9j7AJqCdzzP4gZ1flFHuaArAz6OjYckSGDoUmja9lm4oiqIEDH8G/kKgn4jEiEg0MBi4pUqdMcBKbweLyDgR2SIiWyoFlhqC3PWboYWTNsbQ9uOP4eRJTfMoihJS+C3wG2OKgOeBD4FVwHagvLJcRCYDlwCv6kXGmHnGmBRjTErlM7gNwer9n0LzHgxu08pK88TGwp13Ntj5FSUUyTl2DEd+PmHr1uHIzyfn2LF6na9SorhXr14kJydfIUecnZ1NkyZN+Pbbb122StnlpKQkunTpQv/+/a+QZ1i4cCE9e/YkMTGRXr168fjjj3P69GnAEnPr0qWL6xn/4cOH16sN1zN+1eoxxrwGvAYgIs8Bh+zt0cAvgIHmGk8k2B3xJdzwrwyJjIJ334UxY6xF1RVFuSpyjh1j3N69nKuoAKDkwgXG7d0LQEabNld1TneZ5A8++IBJkybxySefuMpzc3O57bbb+Mc//sFjjz3msrtr8Wzfvp17772XqKgoBg4cyKpVq5g5cyYrV64kLi6O8vJyFixYwLFjx2hh63Xl5OSQknLFY++NDr8GfhFpbYw5LiLxwDDgpyJyN/B/gX81xpzz5/WrUnamnHPxlu7Fv61bZ622pWkeRamWzH372H72rM/yTWVlXKgyfjtXUcHYPXv425EjXo9xNm1KdufOtbp+WVkZN1cq6AIHDhzg7NmzzJ07l6ysLI/A73ENp5Nnn32WV155hYEDB5KVlcX06dOJi4sDrF8VY8aMqZUPjQ1/q3O+LSIxwEVgvDHmtIi8AkQCH9niQ5uMMU/42Q8AFn9SCLFdifnhIs0XLYL27SE19VpcWlEaLVWDfk322lCplnn+/HmOHj3qIYKWl5fHiBEj6NevH3v37uXYsWO08fHLIjk5mRdffBGAXbt2ecg7eCMjI4Moe8nVtLQ017GNDX+nevp5sQVMDGf5559Cnx7cd6kc1qyBSZNUiVNRaqCmkbkjP58SLzo1CZGRrEtKuqpruqd68vPzefTRRyksLEREyM3NZdmyZYSFhXH//fezZMkSnnrqKa/n8ZVJ3rlzJyNHjuTMmTM899xzPGTP2g+VVE9Izdzd/MM+uCGa8Z99BhUVmuZRlAYgq0MHosM8Q0l0WBhZHTo0yPlTU1M5ceIEpaWl7Ny5k3379pGWlobD4SAvL69aZcxt27a59GsSExPZunUrAD169GD79u0MGjSI77//vkH8DCZCJvAbAyfa/ABA4vLlkJQEKkKlKPUmo00b5nXpQkJkJII10p/XpctV39ityp49eygvLycmJobc3FymTJnikkQ+cuQIR44coaTkyoVgduzYwdSpUxk/fjxgLdwyceJEDh065KoTikEfQmgFro07jmJ+nEDSvn1EFBSAm4a3oij1I6NNmwYL9HA5xw9WumbBggWEh4eTl5fH+++/71H3vvvuIy8vjz59+rBhwwaSkpI4d+4crVu3ZtasWQwcOBCAwYMHU1payqBBgygvL6dFixZ0796du+6663I73HL8sbGxrF69usHadD0RMoH/rY350KU7/7l8sZXXHzEi0C4piuKD8vJyr/Yvv/zyCtuMGTNc2+7P9Xtj1KhRjBo1ymtZbRdjbwyETKrnw9NFENaEoevXwYABYD/SpSiKEmqETOAvaX6W24uKaFZcrDd1FUUJaUIi8B8/eZ5LbVsxauX7EBkJw4YF2iVFUZSAERKB/411Wwhv2oUR/9wI6enQvHmgXVIURQkYIXFzd1HJDv7t4llanj6taR5FUUKekBjxF0WeJuOjj6ho0QIGDQq0O4qiKAGl0Qf+8nKD+dGN3PfPfxL2wANWjl9RlIYlJwccDggLs95zvKqt15pKWebu3buTnp7ukk6uxOl0MqLKI9mjR48mLi6OC7Z8xIkTJ3A4HAAUFxcTFRVFUlISXbt25fbbb+f111/3OP6dd96hZ8+edO3alR49evDOO+94nDs6OpozZ864bJmZmYgIJ06cqFdbA0GjD/z//dk+hu4+QVNV4lQU/5CTA+PGQUmJNUW+pMTar0fwr9TqKSwspGXLlsyZM8dVVlRURHl5ORs2bOC7777zOC48PJz58+d7PWfHjh3Ztm0bRUVF5OXlkZ2dzd///ncAPv/8cyZOnMjy5cspKiri3XffZeLEiezYscN1fKdOnVi+fDkAFRUVrF271qX0GWw0+sD/6q6tZKxdx+k2baDfFZpxiqLURGYm/Pznvl9jx8K5Kgrr585Zdl/HZGbW+vKpqakcPnzYtZ+bm8vIkSO58847XYH4squZzJw5k0uXLlU9jQcdOnRgxowZzJo1C4Dp06fzzDPP0L59ewDat2/PpEmTPNQ5R4wYwaJFiwBrstfPfvYzbrghOG+TNvrAf+DUl9z12Wfc+O//bv0MVRSlYfGizFmtvQ6Ul5ezZs0a7rnnHpdt0aJFjBgxgocffvgKgbb4+Hj69u3Lm2++WeO5k5OT2bNnD2BJNvfu3dujPCUlhV27drn2b731VkpLSzl16hS5ublXpJqCieD8d1UH0vbs5IaKCm549NFAu6IowUl2dvXlDoeV3qlKQgJcpQxCpVbP4cOH6dq1K2lpaQBs2bKF2NhY4uPjiYuLY8yYMZw8eZKWLVu6jp00aRJDhw5lyJAh1V7jahb/GzZsGHl5eWzevJm//vWvdT7+eqHRDoGf+3UmxW1aMfu1PH4ID+e5V73n/RRFqSdZWRAd7WmLjrbsV0lljr+kpARjjCvHn5uby549e3A4HHTs2JGysjLefvttj2M7d+6M0+lk8eLF1V7DXbK5W7duFBQUeJQXFBSQmJjoYXvooYf44x//SFpaGmHBnEEwxlz3r969e5u6kPXkBHM2MtIY61aTMWDORkaarCcn1Ok8ihKq7N69u24HLFxoTEKCMSLW+8KF9br+TTfd5NreunWriY+PNxcuXDDt2rUzhw8fdpWtXbvW3HHHHcYYY0aNGmWWLFlijDGmsLDQJCQkmISEBGOMMQcPHjSJiYmu4w4ePGiSkpLM/PnzjTHGbNu2zXTq1MkcPHjQVd6xY0ezbdu2K8796quvmv379xtjjElISDClpaX1amtD4a3PgC3GS0xtlKmeR5bmcFOV/OJNFy7wyNIcmFvDz1ZFUepORobfnppLSkqiZ8+eTJs2jbi4OH7yk5+4yvr378/u3bs5evSoxzGJiYkkJye7Fl4Ba63epKQkzp8/T7NmzfjNb37D6NGjAevx0Oeff5709HQuXrxIREQEL7zwgksa2p1f/epXfmnntURMPdbFvFakpKSYLVu21Lp+RVgYYV7aVSFCWEVFQ7qmKI2SoqIiVxpECQ689ZmIFBhjrlhLMoiTVL75KjamTnZFUZRQolEG/reGZ/BdlRm630VG8tZwncClKIri18AvIhNEpFBEdolIpm17wN6vEBG/LGf/zNxsXh7zBMWtYqkQobhVLC+PeYJnNL+vKLUmGNLAikVd+8pvOX4R6Q7kAbcDPwCrgCeACKAC+Csw0RhTY/K+rjl+RVHqx8GDB2nWrBkxMTGISKDdUarBGMM333zDmTNnXDOPK/GV4/fnUz1dgc3GmHO2A58Aw4wxL9j7fry0oij1oV27dhw6dIjS0tJAu6LUgiZNmtCuXbta1/dn4C8EskQkBvgeGAzUetguIuOAcWBNw1YU5doRERFxxehRaTz4LcdvjCkCngc+xErzbAfK63D8PGNMijEmpVWrVn7yUlEUJfTw681dY8xrxpjexpj+wCngC39eT1EURakZv87cFZHWxpjjIhIPDAN+6s/rKYqiKDXj15m7IrIBiAEuAv9pjFkjIvcBs4FWwGlguzHmrhrOUwp4kf/zO7FA8C2vcxn1P/AEexvU/8BTnzYkGGOuyJUHhWRDoBCRLd4ehQoW1P/AE+xtUP8Djz/a0Chn7iqKoii+0cCvKIoSYmjgr555gXagnqj/gSfY26D+B54Gb4Pm+BVFUUIMHfEriqKEGBr4FUVRQoyQDvwiUiwiO0Vku4hssW0tReQjEdlnv99s20VEZonIfhHZISLJAfJ5vogcF5FCN1udfRaRUXb9fSIyKsD+TxGRw3Y/bBeRwW5lk2z/94rIXW72u23bfhF5+hr6f4uIfCwiu2158Qm2PSj6oBr/g6IPRKSJiPyPiHxu+/9n295eRDbbviwSkRtte6S9v98ud9TUrgC24XUROejWB07b3vDfIW8L8YbKCygGYqvYXgCetrefBp63twcDKwHBmoG8OUA+9weSgcKr9RloCXxpv99sb98cQP+nYEl0V63bDfgciATaAweAcPt1AOgA3GjX6XaN/G8LJNvbzbBkSLoFSx9U439Q9IH9OTa1tyOAzfbnuhgYYdtfBZ60t38NvGpvjwAWVdeua/Qd8tWG14HhXuo3+HcopEf8PhgKLLC3FwD3utnfMBabgBYi0vZaO2eMWQ+crGKuq893AR8ZY04aY04BHwF3+997n/77YiiQZ4y5YIw5COzHWt/hdmC/MeZLY8wPWOs+DPWLw1Uwxhw1xmy1t88ARUAcQdIH1fjvi+uqD+zP8ay9G2G/DDAAWGrbq37+lf2yFBgoIoLvdvmdatrgiwb/DoV64DfAhyJSIJYMNEAbY8xRe/t/gTb2dhzwtduxh6j+D+ZaUlefr8e2PGX/jJ1fmSbhOvffThskYY3Ygq4PqvgPQdIHIhIuItuB41jB7gBw2hhzyYsvLj/t8m+xZGQC+vlXbYMxprIPsuw+mCkilevHNngfhHrg72uMSQYGAeNFpL97obF+TwXV867B6DPwF6Aj4ASOAi8F1p2aEZGmwNtApjGmzL0sGPrAi/9B0wfGmHJjjBNohzVK/5cAu1RnqrZBrBULJ2G15Tas9M3/89f1QzrwG2MO2+/HgWVYX6JjlSkc+/24Xf0wcIvb4e1s2/VAXX2+rtpijDlm/yFUAH/j8k/u69J/EYnACpo5xph/2Oag6QNv/gdbHwAYY04DHwOpWOmPSrVhd19cftrlzYFvuA78B4823G2n4Ywx5gLwd/zYByEb+EXkJhFpVrkN3Im1ati7QOXd8VHAcnv7XeBR+w77T4Fv3X7aB5q6+vwBcKeI3Gz/pL/TtgWEKvdK7sPqB7D8H2E/mdEe6Az8D/AZ0Nl+kuNGrJt2714jXwV4DSgyxsxwKwqKPvDlf7D0gYi0EpEW9nYUkIZ1n+JjYLhdrernX9kvw4G19i8yX+3yOz7asMdt4CBY9yjc+6Bhv0NXe2c62F9YTyN8br92AZNtewywBtgHrAZamst34udg5RN3AikB8jsX66f4Rayc3tir8RkYg3VDaz/wWID9f9P2b4f9JW/rVn+y7f9eYJCbfTDWEykHKvvuGvnfFyuNswNrVbntti9B0QfV+B8UfQD0BLbZfhYCz9r2DliBez+wBIi07U3s/f12eYea2hXANqy1+6AQWMjlJ38a/Dukkg2KoighRsimehRFUUIVDfyKoighhgZ+RVGUEEMDv6IoSoihgV9RFCXE0MCvBDUiYkTkJbf9iSIypQHOGykiq22VxIeqlL0uIsN9Haso1zsa+JVg5wIwTERiG/i8SQDGGKcxZlEDn1tRAooGfiXYuYS1JulvqxaIiENE1tqiV2tEJN5LnZYi8o5dZ5OI9BSR1lgTaG6zR/wdfV1crDUdptn1tohIsoh8ICIHROQJu05T+/pbxVr/Yajb8X8USw/+nyKSKyITbXtHEVklloDgBhH5F9v+gIgUiqXlvr6+H54SmmjgVxoDc4AMEWlexT4bWGCM6QnkALO8HPtnYJtd5xks+dvjwOPABnvEf6CG639lLMGtDdia6li66X+2y88D9xlLEPAO4CV7+v1twP1ALyyhwBS3c84D/sMY0xuYCMy17c8CdxljegH31OCXonjlhpqrKMr1jTGmTETeAH4DfO9WlAoMs7ffxFospSp9sYIvxpi1IhIjIj+qowuVGjU7sabZnwHOiMgFW5PlO+A5sdRfK7Ckc9sAPwOWG2POA+dF5D1wKWf+H2CJJdsCWAuGAGwEXheRxUClQJyi1AkN/EpjIRvYiqVqeK25YL9XuG1X7t8AZACtgN7GmIsiUoylIeOLMCx9eWfVAmPMEyLSBxgCFIhIb2PMNw3QBiWE0FSP0igwxpzEWn5vrJv5UyzVSLCC7wYvh26wyxCRnwMnTBV9/QagOXDcDvp3AAm2fSOQLtYarE2BX9htKQMOisgDtl8iIr3s7Y7GmM3GmGeBUjxleRWlVmjgVxoTLwHuT/f8B/CYiOwARgITvBwzBeht1/kvLkv4NiQ5QIqI7AQeBfYAGGM+w0oT7cBaU3Un1gpRYP0zGisileqxlTeEX7RvEBdi/WP73A/+Ko0cVedUlAAiIk2NMWdFJBpYD4wz9pq4iuIvNMevKIFlnoh0w8r5L9Cgr1wLdMSvKIoSYmiOX1EUJcTQwK8oihJiaOBXFEUJMTTwK4qihBga+BVFUUKM/w8pU21U3hDBZgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}