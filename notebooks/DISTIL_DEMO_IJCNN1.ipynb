{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DISTIL_DEMO_IJCNN1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUq3Jx0yl_7R",
        "outputId": "e4061d54-4caf-4eb0-f1af-63e9ae041a1c"
      },
      "source": [
        "#pip install --extra-index-url https://test.pypi.org/simple/ decile-distil\n",
        "!git clone https://github.com/decile-team/distil.git\n",
        "!pip install apricot-select"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'distil'...\n",
            "remote: Enumerating objects: 431, done.\u001b[K\n",
            "remote: Counting objects: 100% (431/431), done.\u001b[K\n",
            "remote: Compressing objects: 100% (296/296), done.\u001b[K\n",
            "remote: Total 431 (delta 202), reused 334 (delta 117), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (431/431), 10.13 MiB | 26.19 MiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n",
            "Requirement already satisfied: apricot-select in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from apricot-select) (0.48.0)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from apricot-select) (1.3.7)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from apricot-select) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.6/dist-packages (from apricot-select) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.6/dist-packages (from apricot-select) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->apricot-select) (51.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->apricot-select) (0.31.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FGBiR9n44ZH",
        "outputId": "e85397da-8faf-4ad4-c4d9-c6e2fb9c72e5"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 16390813701197650059, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14638920512\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 12189765373925270788\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh4KW8FCKGUM"
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "\n",
        "from distil.distil.utils.DataHandler import DataHandler_Points\n",
        "from distil.distil.active_learning_strategies import GLISTER,BADGE,EntropySampling\n",
        "from distil.distil.utils.models.simpleNN_net import TwoLayerNet\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWTSW0qchnap"
      },
      "source": [
        "### **Loading data**\n",
        "IJCNN1 is a binary classification Dataset with 49,990 samples and 22 features. The following code snippet can be used to read datasets in the svmlight / libsvm format into numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7jR5KBikpbg"
      },
      "source": [
        "def libsvm_file_load(path,dim, save_data=False):\n",
        "    data = []\n",
        "    target = []\n",
        "    with open(path) as fp:\n",
        "       line = fp.readline()\n",
        "       while line:\n",
        "        temp = [i for i in line.strip().split(\" \")]\n",
        "        target.append(int(float(temp[0]))) # Class Number. # Not assumed to be in (0, K-1)\n",
        "        temp_data = [0]*dim\n",
        "        \n",
        "        for i in temp[1:]:\n",
        "            ind,val = i.split(':')\n",
        "            temp_data[int(ind)-1] = float(val)\n",
        "        data.append(temp_data)\n",
        "        line = fp.readline()\n",
        "    X_data = np.array(data,dtype=np.float32)\n",
        "    Y_label = np.array(target)\n",
        "    if save_data:\n",
        "        # Save the numpy files to the folder where they come from\n",
        "        data_np_path = path + '.data.npy'\n",
        "        target_np_path = path + '.label.npy'\n",
        "        np.save(data_np_path, X_data)\n",
        "        np.save(target_np_path, Y_label)\n",
        "    return (X_data, Y_label)\n",
        "\n",
        "    \n",
        "trn_file = 'distil/datasets/ijcnn1/ijcnn1.trn'\n",
        "val_file = 'distil/datasets/ijcnn1/ijcnn1.val'\n",
        "tst_file = 'distil/datasets/ijcnn1/ijcnn1.tst'\n",
        "data_dims = 22\n",
        "num_cls = 2\n",
        "x_trn, y_trn = libsvm_file_load(trn_file, dim=data_dims)\n",
        "x_val, y_val = libsvm_file_load(val_file, dim=data_dims)\n",
        "x_tst, y_tst = libsvm_file_load(tst_file, dim=data_dims)\n",
        "\n",
        "# The class labels are (-1,1). Make them to (0,1)\n",
        "y_trn[y_trn < 0] = 0\n",
        "y_val[y_val < 0] = 0\n",
        "y_tst[y_tst < 0] = 0    \n",
        "\n",
        "sc = StandardScaler()\n",
        "x_trn = sc.fit_transform(x_trn)\n",
        "x_val = sc.transform(x_val)\n",
        "x_tst = sc.transform(x_tst)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t6z0vY7nNP5"
      },
      "source": [
        "# **Class for training**\n",
        "\n",
        "Although in this tutorial we mimic real world active learning setting with datasets which has all the labels, usually in a active learning settings it may take quite some time to label new set points. Therefore it is a good idea to create training class which can store current model state which can be restored later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbof4G2hnbpg"
      },
      "source": [
        "def init_weights(m):\n",
        "    torch.manual_seed(42)\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "class data_train:\n",
        "\n",
        "    def __init__(self, X, Y, net, handler, args):\n",
        "\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.net = net\n",
        "        self.handler = handler\n",
        "        self.args = args\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "\n",
        "    def update_index(self, idxs_lb):\n",
        "        self.idxs_lb = idxs_lb\n",
        "\n",
        "    def update_data(self, X, Y):\n",
        "      \n",
        "      self.X = X\n",
        "      self.Y = Y\n",
        "      self.n_pool = len(Y)\n",
        "\n",
        "    def _train(self, epoch, loader_tr, optimizer):\n",
        "        self.clf.train()\n",
        "        accFinal = 0.\n",
        "\n",
        "        for batch_id, (x, y, idxs) in enumerate(loader_tr):\n",
        "            if self.use_cuda:\n",
        "                x, y = Variable(x.cuda()), Variable(y.cuda())\n",
        "            else:\n",
        "                x, y = Variable(x), Variable(y)\n",
        "            optimizer.zero_grad()\n",
        "            out = self.clf(x)\n",
        "            loss = F.cross_entropy(out, y)\n",
        "            accFinal += torch.sum((torch.max(out,1)[1] == y).float()).data.item()\n",
        "            loss.backward()\n",
        "\n",
        "            # clamp gradients, just in case\n",
        "            # for p in filter(lambda p: p.grad is not None, self.clf.parameters()): p.grad.data.clamp_(min=-.1, max=.1)\n",
        "\n",
        "            optimizer.step()\n",
        "        return accFinal / len(loader_tr.dataset.X)\n",
        "\n",
        "    \n",
        "    def train(self):\n",
        "\n",
        "        #print('Training..')\n",
        "        def weight_reset(m):\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                m.reset_parameters()\n",
        "\n",
        "        n_epoch = self.args['n_epoch']\n",
        "        if self.use_cuda:\n",
        "            self.clf =  self.net.apply(weight_reset).cuda()\n",
        "        else:\n",
        "            self.clf =  self.net.apply(weight_reset)\n",
        "\n",
        "        optimizer = optim.Adam(self.clf.parameters(), lr = self.args['lr'], weight_decay=0)\n",
        "        loader_tr = DataLoader(self.handler(self.X, self.Y, False),shuffle=True, batch_size = args['batch_size'])\n",
        "        epoch = 1\n",
        "        accCurrent = 0\n",
        "        while accCurrent < 0.95 and epoch < n_epoch: \n",
        "            accCurrent = self._train(epoch, loader_tr, optimizer)\n",
        "            epoch += 1\n",
        "            # print(str(epoch) + ' training accuracy: ' + str(accCurrent), flush=True)\n",
        "            \n",
        "            if (epoch % 50 == 0) and (accCurrent < 0.2): # resetif not converging\n",
        "                self.clf = self.net.apply(weight_reset)\n",
        "                optimizer = optim.Adam(self.clf.parameters(), lr = self.args['lr'], weight_decay=0)\n",
        "\n",
        "        print('Training accuracy:',round(accCurrent, 3)*100, flush=True) #'Epoch:', str(epoch),\n",
        "        return self.clf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KrEWA8ln4BO"
      },
      "source": [
        "# **Trainig loop for active learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJIZ-mtqn3qQ"
      },
      "source": [
        "def training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=False):\n",
        "\n",
        "    flag = False\n",
        "    if first:\n",
        "\n",
        "      nSamps, dim = np.shape(X_unlabeled)\n",
        "\n",
        "      np.random.seed(42)\n",
        "      start_idxs = np.random.choice(nSamps, size=int(0.01*nSamps), replace=False)\n",
        "\n",
        "      X_tr = X_unlabeled[start_idxs]\n",
        "      X_unlabeled = np.delete(X_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "      Y_tr = Y_unlabeled[start_idxs]\n",
        "      Y_unlabeled = np.delete(Y_unlabeled, start_idxs, axis = 0)\n",
        "\n",
        "      print('Starting set of points -', len(start_idxs))\n",
        "\n",
        "    else:    \n",
        "\n",
        "      #Human In Loop, Assuming user adds new labels here\n",
        "      idx = strategy.select(budget)\n",
        "      \n",
        "      #Adding new points to training set\n",
        "      X_tr = np.concatenate((X_tr, X_unlabeled[idx]), axis=0)\n",
        "      X_unlabeled = np.delete(X_unlabeled, idx, axis = 0)\n",
        "\n",
        "      Y_tr = np.concatenate((Y_tr, Y_unlabeled[idx]), axis = 0)\n",
        "      Y_unlabeled = np.delete(Y_unlabeled, idx, axis = 0)\n",
        "\n",
        "      print('Number of training points -',X_tr.shape[0])\n",
        "    \n",
        "    strategy.update_data(X_tr, Y_tr, X_unlabeled)\n",
        "    dt.update_data(X_tr, Y_tr)\n",
        "\n",
        "    clf = dt.train()\n",
        "    strategy.update_model(clf)\n",
        "    y_pred = strategy.predict(x_tst).numpy()\n",
        "    acc = round(1.0 * (y_tst == y_pred).sum().item() / len(y_tst), 3)\n",
        "    #print('Testing accuracy:', acc, flush=True)\n",
        "    if acc > 0.98:\n",
        "        flag = True\n",
        "        print('Testing accuracy reached above 98%')\n",
        "\n",
        "    return X_tr,Y_tr,X_unlabeled,Y_unlabeled,acc, flag"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRm2tsuwqQEP"
      },
      "source": [
        "# **Uncertanity based Active learning Strategy**\n",
        "\n",
        "The most basic active learning strategy, where we select samples about which the model is most uncertain. To quantify the uncertainity we use entropy, therefore select points which have maximum entropy. Let $z_i$ be output from the model then the correponding softmax would be $$\\sigma(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}$$. Then entropy can be calculated as, $$ENTROPY = -\\sum_j \\sigma(z_j)*log(\\sigma(z_i))$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSBY1RRKqPye",
        "outputId": "ea71569b-7caf-4969-ae11-144a4a729c89"
      },
      "source": [
        "net = TwoLayerNet(data_dims, num_cls,40)\n",
        "net.apply(init_weights)\n",
        "\n",
        "strategy_args = {'batch_size' : 1000, 'lr':float(0.001)} \n",
        "strategy = EntropySampling(None, None, None, net, DataHandler_Points, num_cls, strategy_args)\n",
        "\n",
        "args = {'n_epoch':100, 'lr':float(0.001),'batch_size':1000}  #Different args than strategy_args\n",
        "n_rounds = 10    ##Number of rounds to run ac\n",
        "budget = int(0.01*x_trn.shape[0])    ##Number of new data points after every iteration\n",
        "\n",
        "#Training Class initialization\n",
        "dt = data_train(None, None, net, DataHandler_Points, args)\n",
        "\n",
        "un_acc = np.zeros(n_rounds+1)\n",
        "X_unlabeled = deepcopy(x_trn)\n",
        "Y_unlabeled = deepcopy(y_trn)\n",
        "X_tr = None\n",
        "Y_tr = None\n",
        "\n",
        "X_tr,Y_tr,X_unlabeled,Y_unlabeled,un_acc[0],_ = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=True)\n",
        "print('Initial Testing accuracy:', round(un_acc[0], 3)*100, flush=True)\n",
        "\n",
        "for i in range(n_rounds):\n",
        "   print('-------------------------------------------------')\n",
        "   print('Round', i) \n",
        "   print('-------------------------------------------------')\n",
        "   \n",
        "   X_tr,Y_tr,X_unlabeled,Y_unlabeled,un_acc[i+1],flag = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst)\n",
        "   print('Testing accuracy at',i+1,'round :', round(un_acc[i+1], 3)*100, flush=True)  \n",
        "   \n",
        "   if flag:\n",
        "     break\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting set of points - 350\n",
            "Training accuracy: 88.6\n",
            "Initial Testing accuracy: 90.5\n",
            "-------------------------------------------------\n",
            "Round 0\n",
            "-------------------------------------------------\n",
            "Number of training points - 700\n",
            "Training accuracy: 86.9\n",
            "Testing accuracy at 1 round : 89.8\n",
            "-------------------------------------------------\n",
            "Round 1\n",
            "-------------------------------------------------\n",
            "Number of training points - 1050\n",
            "Training accuracy: 86.0\n",
            "Testing accuracy at 2 round : 92.7\n",
            "-------------------------------------------------\n",
            "Round 2\n",
            "-------------------------------------------------\n",
            "Number of training points - 1400\n",
            "Training accuracy: 89.0\n",
            "Testing accuracy at 3 round : 93.4\n",
            "-------------------------------------------------\n",
            "Round 3\n",
            "-------------------------------------------------\n",
            "Number of training points - 1750\n",
            "Training accuracy: 89.0\n",
            "Testing accuracy at 4 round : 95.0\n",
            "-------------------------------------------------\n",
            "Round 4\n",
            "-------------------------------------------------\n",
            "Number of training points - 2100\n",
            "Training accuracy: 88.2\n",
            "Testing accuracy at 5 round : 95.39999999999999\n",
            "-------------------------------------------------\n",
            "Round 5\n",
            "-------------------------------------------------\n",
            "Number of training points - 2450\n",
            "Training accuracy: 88.7\n",
            "Testing accuracy at 6 round : 96.0\n",
            "-------------------------------------------------\n",
            "Round 6\n",
            "-------------------------------------------------\n",
            "Number of training points - 2800\n",
            "Training accuracy: 88.9\n",
            "Testing accuracy at 7 round : 96.7\n",
            "-------------------------------------------------\n",
            "Round 7\n",
            "-------------------------------------------------\n",
            "Number of training points - 3150\n",
            "Training accuracy: 89.0\n",
            "Testing accuracy at 8 round : 96.6\n",
            "-------------------------------------------------\n",
            "Round 8\n",
            "-------------------------------------------------\n",
            "Number of training points - 3500\n",
            "Training accuracy: 89.0\n",
            "Testing accuracy at 9 round : 96.89999999999999\n",
            "-------------------------------------------------\n",
            "Round 9\n",
            "-------------------------------------------------\n",
            "Number of training points - 3850\n",
            "Training accuracy: 89.1\n",
            "Testing accuracy at 10 round : 97.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C-rsSkOqdKA"
      },
      "source": [
        "# **GLISTER**\n",
        "This is implemetation of GLISTER-ACTIVE from the paper [GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning](https://arxiv.org/abs/2012.10630). GLISTER methods tries to solve a bi-level optimisation problem.\n",
        "\\begin{equation*}\n",
        "\\overbrace{\\underset{{S \\subseteq {\\mathcal U}, |S| \\leq k}}{\\operatorname{argmax\\hspace{0.7mm}}} LL_V(\\underbrace{\\underset{\\theta}{\\operatorname{argmax\\hspace{0.7mm}}} LL_T( \\theta, S)}_{inner-level}, {\\mathcal V})}^{outer-level}\n",
        "\\end{equation*}\n",
        "where is $S$ is set of points selected at each round,${\\mathcal V}$ could be a dedicated validation set with labled points or could be union of labeled and unlabeled points with hypothesised labels, $k$ is the budget.\n",
        "To set ${\\mathcal V}$ to be validation set, while calling **GLISTER** class in the toolkit set _valid=TRUE_ and pass validation set otherwise set _valid=False_.\n",
        "\n",
        "Solving this problem directly is almost impossible, therefore we resort to one-step approxiations.We start we $S^0$ as empty set and bulid it as $S^k = S^{k-1} \\cup e$, where $e$ is $\\underset{e}{\\operatorname{argmax\\hspace{0.7mm}}} G_{\\theta}(e | S^k)$. We define,$$G_{\\theta}(e | S^k) = LL_{V}(\\theta^{k}, {\\mathcal V})$$ and update $$\\theta^k \\leftarrow \\theta^{k-1} -  \\eta \\nabla_{\\theta} LL_T(\\hat{\\theta}, e)$$ where $\\hat{\\theta}$ is the parameters of the model at the begining of the selection.\n",
        "To prevent overfitting, we can add regularizer to GLISTER, which can be set by **_typeOf_**. **_typeOf_** can be set to - **'none'**(which is default) for normal GLISTER,**'Rand'** for replacing **_lam_** fraction of points replaced by random points, **'Diversity'** adding diversity set function while computing gain and **'FacLoc'** adding Facility Location set function while computing gain. **_lam_** for both **'Diversity'** and **'FacLoc'** determines the weightage given to them while computing the gain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_gJF_i7TdrD",
        "outputId": "3d5c579a-048f-4ec7-b9eb-e5b3ca749af1"
      },
      "source": [
        "net = TwoLayerNet(data_dims, num_cls,40)\n",
        "net.apply(init_weights)\n",
        "\n",
        "strategy_args = {'batch_size' : 12000, 'lr':float(0.001)} \n",
        "strategy = GLISTER(None, None, None, net, DataHandler_Points, num_cls, strategy_args,valid=False,typeOf='Diversity',lam=5)\n",
        "\n",
        "args = {'n_epoch':100, 'lr':float(0.001),'batch_size':1000}  #Different args than strategy_args\n",
        "n_rounds = 10    ##Number of rounds to run ac\n",
        "budget = int(0.01*x_trn.shape[0])     ##Number of new data points after every iteration\n",
        "\n",
        "#Training Class initialization\n",
        "dt = data_train(None, None, net, DataHandler_Points, args)\n",
        "\n",
        "glister_acc = np.zeros(n_rounds+1)\n",
        "X_unlabeled = deepcopy(x_trn)\n",
        "Y_unlabeled = deepcopy(y_trn)\n",
        "X_tr = None\n",
        "Y_tr = None\n",
        "\n",
        "X_tr,Y_tr,X_unlabeled,Y_unlabeled,glister_acc[0],_ = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=True)\n",
        "print('Initial Testing accuracy:', round(glister_acc[0], 3)*100, flush=True)\n",
        "\n",
        "for i in range(n_rounds):\n",
        "  \n",
        "  print('-------------------------------------------------')\n",
        "  print('Round', i) \n",
        "  print('-------------------------------------------------')\n",
        "\n",
        "  X_tr,Y_tr,X_unlabeled,Y_unlabeled,glister_acc[i+1],flag = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst)\n",
        "  print('Testing accuracy at',i+1,'round :', round(glister_acc[i+1], 3)*100, flush=True)  \n",
        "  if flag:\n",
        "    break\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting set of points - 350\n",
            "Training accuracy: 88.6\n",
            "Initial Testing accuracy: 90.5\n",
            "-------------------------------------------------\n",
            "Round 0\n",
            "-------------------------------------------------\n",
            "Number of training points - 700\n",
            "Training accuracy: 88.4\n",
            "Testing accuracy at 1 round : 86.6\n",
            "-------------------------------------------------\n",
            "Round 1\n",
            "-------------------------------------------------\n",
            "Number of training points - 1050\n",
            "Training accuracy: 87.2\n",
            "Testing accuracy at 2 round : 90.3\n",
            "-------------------------------------------------\n",
            "Round 2\n",
            "-------------------------------------------------\n",
            "Number of training points - 1400\n",
            "Training accuracy: 90.4\n",
            "Testing accuracy at 3 round : 91.9\n",
            "-------------------------------------------------\n",
            "Round 3\n",
            "-------------------------------------------------\n",
            "Number of training points - 1750\n",
            "Training accuracy: 89.8\n",
            "Testing accuracy at 4 round : 93.30000000000001\n",
            "-------------------------------------------------\n",
            "Round 4\n",
            "-------------------------------------------------\n",
            "Number of training points - 2100\n",
            "Training accuracy: 87.0\n",
            "Testing accuracy at 5 round : 93.7\n",
            "-------------------------------------------------\n",
            "Round 5\n",
            "-------------------------------------------------\n",
            "Number of training points - 2450\n",
            "Training accuracy: 88.8\n",
            "Testing accuracy at 6 round : 94.19999999999999\n",
            "-------------------------------------------------\n",
            "Round 6\n",
            "-------------------------------------------------\n",
            "Number of training points - 2800\n",
            "Training accuracy: 89.2\n",
            "Testing accuracy at 7 round : 95.19999999999999\n",
            "-------------------------------------------------\n",
            "Round 7\n",
            "-------------------------------------------------\n",
            "Number of training points - 3150\n",
            "Training accuracy: 88.2\n",
            "Testing accuracy at 8 round : 95.39999999999999\n",
            "-------------------------------------------------\n",
            "Round 8\n",
            "-------------------------------------------------\n",
            "Number of training points - 3500\n",
            "Training accuracy: 88.4\n",
            "Testing accuracy at 9 round : 96.3\n",
            "-------------------------------------------------\n",
            "Round 9\n",
            "-------------------------------------------------\n",
            "Number of training points - 3850\n",
            "Training accuracy: 88.8\n",
            "Testing accuracy at 10 round : 96.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwrpLSGRUYZw"
      },
      "source": [
        "# **BADGE**\n",
        "This method is based on the paper [Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds](https://arxiv.org/abs/1906.03671). Here at each around of selection loss gradients are computed using the hypothesised lables. Then to points to be labled are selected by applying k-means++ on these loss gradients. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEtuF8O29fwh",
        "outputId": "6ebd0a7c-423b-4634-ee71-6754bea01c5d"
      },
      "source": [
        "net = TwoLayerNet(data_dims, num_cls,40)\n",
        "net.apply(init_weights)\n",
        "\n",
        "strategy_args = {'batch_size' : 12000, 'lr':float(0.001)} \n",
        "strategy = BADGE(None, None, None, net, DataHandler_Points, num_cls, strategy_args)\n",
        "\n",
        "args = {'n_epoch':100, 'lr':float(0.001),'batch_size':1000}  #Different args than strategy_args\n",
        "n_rounds = 10    ##Number of rounds to run ac\n",
        "budget = int(0.01*x_trn.shape[0])     ##Number of new data points after every iteration\n",
        "\n",
        "#Training Class initialization\n",
        "dt = data_train(None, None, net, DataHandler_Points, args)\n",
        "\n",
        "badge_acc = np.zeros(n_rounds+1)\n",
        "X_unlabeled = deepcopy(x_trn)\n",
        "Y_unlabeled = deepcopy(y_trn)\n",
        "X_tr = None\n",
        "Y_tr = None\n",
        "\n",
        "X_tr,Y_tr,X_unlabeled,Y_unlabeled,badge_acc[0],_ = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=True)\n",
        "print('Initial Testing accuracy:', round(badge_acc[0], 3)*100, flush=True)\n",
        "\n",
        "for i in range(n_rounds):\n",
        "  print('-------------------------------------------------')\n",
        "  print('Round', i) \n",
        "  print('-------------------------------------------------')\n",
        "\n",
        "  X_tr,Y_tr,X_unlabeled,Y_unlabeled,badge_acc[i+1],flag = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst)\n",
        "  print('Testing accuracy at',i+1,'round :', round(badge_acc[i+1], 3)*100, flush=True)  \n",
        "  if flag:\n",
        "    break\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting set of points - 350\n",
            "Training accuracy: 88.6\n",
            "Initial Testing accuracy: 90.5\n",
            "-------------------------------------------------\n",
            "Round 0\n",
            "-------------------------------------------------\n",
            "Number of training points - 700\n",
            "Training accuracy: 85.6\n",
            "Testing accuracy at 1 round : 91.0\n",
            "-------------------------------------------------\n",
            "Round 1\n",
            "-------------------------------------------------\n",
            "Number of training points - 1050\n",
            "Training accuracy: 87.3\n",
            "Testing accuracy at 2 round : 91.0\n",
            "-------------------------------------------------\n",
            "Round 2\n",
            "-------------------------------------------------\n",
            "Number of training points - 1400\n",
            "Training accuracy: 89.0\n",
            "Testing accuracy at 3 round : 91.2\n",
            "-------------------------------------------------\n",
            "Round 3\n",
            "-------------------------------------------------\n",
            "Number of training points - 1750\n",
            "Training accuracy: 87.8\n",
            "Testing accuracy at 4 round : 91.60000000000001\n",
            "-------------------------------------------------\n",
            "Round 4\n",
            "-------------------------------------------------\n",
            "Number of training points - 2100\n",
            "Training accuracy: 88.0\n",
            "Testing accuracy at 5 round : 92.4\n",
            "-------------------------------------------------\n",
            "Round 5\n",
            "-------------------------------------------------\n",
            "Number of training points - 2450\n",
            "Training accuracy: 88.9\n",
            "Testing accuracy at 6 round : 93.60000000000001\n",
            "-------------------------------------------------\n",
            "Round 6\n",
            "-------------------------------------------------\n",
            "Number of training points - 2800\n",
            "Training accuracy: 90.10000000000001\n",
            "Testing accuracy at 7 round : 94.5\n",
            "-------------------------------------------------\n",
            "Round 7\n",
            "-------------------------------------------------\n",
            "Number of training points - 3150\n",
            "Training accuracy: 89.0\n",
            "Testing accuracy at 8 round : 94.1\n",
            "-------------------------------------------------\n",
            "Round 8\n",
            "-------------------------------------------------\n",
            "Number of training points - 3500\n",
            "Training accuracy: 90.0\n",
            "Testing accuracy at 9 round : 95.3\n",
            "-------------------------------------------------\n",
            "Round 9\n",
            "-------------------------------------------------\n",
            "Number of training points - 3850\n",
            "Training accuracy: 89.2\n",
            "Testing accuracy at 10 round : 94.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Hd8PpgnYAYAW",
        "outputId": "73121296-62dd-474c-ca31-a5f5f5ea57fa"
      },
      "source": [
        "x_axis = np.array([budget for i in range(n_rounds+1)])\n",
        "x_axis = x_axis*np.array([i for i in range(1,n_rounds+2)])\n",
        "plt.figure()\n",
        "plt.plot(x_axis, glister_acc, 'b-', label='GLISTER',marker='o')\n",
        "plt.plot(x_axis, un_acc, 'g-', label='Uncertanity',marker='o')\n",
        "plt.plot(x_axis, badge_acc, 'c', label='BADGE',marker='o')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('No of points')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('IJCNN1')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'IJCNN1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}