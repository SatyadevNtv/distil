{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DR8di3vpG_6e"
   },
   "source": [
    "# **Instaling Prerequisites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUq3Jx0yl_7R",
    "outputId": "3db418a9-c93f-45a9-e30f-fb7a261b2f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'distil'...\n",
      "remote: Enumerating objects: 655, done.\u001b[K\n",
      "remote: Counting objects: 100% (655/655), done.\u001b[K\n",
      "remote: Compressing objects: 100% (414/414), done.\u001b[K\n",
      "remote: Total 655 (delta 319), reused 547 (delta 223), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (655/655), 13.16 MiB | 23.52 MiB/s, done.\n",
      "Resolving deltas: 100% (319/319), done.\n",
      "Collecting apricot-select\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/c4/07c964d8f48204a74e98032b3dbfa82f37cafc638fe99a962b6eb9ea0d80/apricot_select-0.6.0-py3-none-any.whl (55kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 3.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from apricot-select) (0.48.0)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.6/dist-packages (from apricot-select) (1.19.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from apricot-select) (1.4.1)\n",
      "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.6/dist-packages (from apricot-select) (4.41.1)\n",
      "Collecting nose\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 9.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->apricot-select) (51.0.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->apricot-select) (0.31.0)\n",
      "Installing collected packages: nose, apricot-select\n",
      "Successfully installed apricot-select-0.6.0 nose-1.3.7\n"
     ]
    }
   ],
   "source": [
    "#pip install --extra-index-url https://test.pypi.org/simple/ decile-distil\n",
    "!git clone https://github.com/decile-team/distil.git\n",
    "!git clone https://github.com/decile-team/datasets.git\n",
    "!pip install apricot-select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FGBiR9n44ZH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hh4KW8FCKGUM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "from distil.distil.utils.data_handler import DataHandler_Points\n",
    "from distil.distil.active_learning_strategies.entropy_sampling import EntropySampling \n",
    "from distil.distil.active_learning_strategies.badge import BADGE\n",
    "from distil.distil.active_learning_strategies.glister import GLISTER\n",
    "from distil.distil.active_learning_strategies.random_sampling import RandomSampling\n",
    "from distil.distil.utils.models.simple_net import TwoLayerNet\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWTSW0qchnap"
   },
   "source": [
    "### **Loading data**\n",
    "IJCNN1 is a binary classification Dataset with 49,990 samples and 22 features. The following code snippet can be used to read datasets in the svmlight / libsvm format into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7jR5KBikpbg"
   },
   "outputs": [],
   "source": [
    "def libsvm_file_load(path,dim, save_data=False):\n",
    "    data = []\n",
    "    target = []\n",
    "    with open(path) as fp:\n",
    "       line = fp.readline()\n",
    "       while line:\n",
    "        temp = [i for i in line.strip().split(\" \")]\n",
    "        target.append(int(float(temp[0]))) # Class Number. # Not assumed to be in (0, K-1)\n",
    "        temp_data = [0]*dim\n",
    "        \n",
    "        for i in temp[1:]:\n",
    "            ind,val = i.split(':')\n",
    "            temp_data[int(ind)-1] = float(val)\n",
    "        data.append(temp_data)\n",
    "        line = fp.readline()\n",
    "    X_data = np.array(data,dtype=np.float32)\n",
    "    Y_label = np.array(target)\n",
    "    if save_data:\n",
    "        # Save the numpy files to the folder where they come from\n",
    "        data_np_path = path + '.data.npy'\n",
    "        target_np_path = path + '.label.npy'\n",
    "        np.save(data_np_path, X_data)\n",
    "        np.save(target_np_path, Y_label)\n",
    "    return (X_data, Y_label)\n",
    "\n",
    "    \n",
    "trn_file = 'datasets/ijcnn1/ijcnn1.trn'\n",
    "val_file = 'datasets/ijcnn1/ijcnn1.val'\n",
    "tst_file = 'datasets/ijcnn1/ijcnn1.tst'\n",
    "data_dims = 22\n",
    "num_cls = 2\n",
    "x_trn, y_trn = libsvm_file_load(trn_file, dim=data_dims)\n",
    "x_val, y_val = libsvm_file_load(val_file, dim=data_dims)\n",
    "x_tst, y_tst = libsvm_file_load(tst_file, dim=data_dims)\n",
    "\n",
    "# The class labels are (-1,1). Make them to (0,1)\n",
    "y_trn[y_trn < 0] = 0\n",
    "y_val[y_val < 0] = 0\n",
    "y_tst[y_tst < 0] = 0    \n",
    "\n",
    "sc = StandardScaler()\n",
    "x_trn = sc.fit_transform(x_trn)\n",
    "x_val = sc.transform(x_val)\n",
    "x_tst = sc.transform(x_tst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8t6z0vY7nNP5"
   },
   "source": [
    "# **Class for training**\n",
    "\n",
    "Although in this tutorial we mimic real world active learning setting with datasets which has all the labels, usually in a active learning settings it may take quite some time to label new set points. Therefore it is a good idea to create training class which can store current model state which can be restored later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbof4G2hnbpg"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    torch.manual_seed(42)\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "class data_train:\n",
    "\n",
    "    def __init__(self, X, Y, net, handler, args):\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.net = net\n",
    "        self.handler = handler\n",
    "        self.args = args\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    def update_index(self, idxs_lb):\n",
    "        self.idxs_lb = idxs_lb\n",
    "\n",
    "    def update_data(self, X, Y):\n",
    "      \n",
    "      self.X = X\n",
    "      self.Y = Y\n",
    "      self.n_pool = len(Y)\n",
    "\n",
    "    def _train(self, epoch, loader_tr, optimizer):\n",
    "        self.clf.train()\n",
    "        accFinal = 0.\n",
    "\n",
    "        for batch_id, (x, y, idxs) in enumerate(loader_tr):\n",
    "            if self.use_cuda:\n",
    "                x, y = Variable(x.cuda()), Variable(y.cuda())\n",
    "            else:\n",
    "                x, y = Variable(x), Variable(y)\n",
    "            optimizer.zero_grad()\n",
    "            out = self.clf(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            accFinal += torch.sum((torch.max(out,1)[1] == y).float()).data.item()\n",
    "            loss.backward()\n",
    "\n",
    "            # clamp gradients, just in case\n",
    "            # for p in filter(lambda p: p.grad is not None, self.clf.parameters()): p.grad.data.clamp_(min=-.1, max=.1)\n",
    "\n",
    "            optimizer.step()\n",
    "        return accFinal / len(loader_tr.dataset.X)\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "\n",
    "        #print('Training..')\n",
    "        def weight_reset(m):\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                m.reset_parameters()\n",
    "\n",
    "        n_epoch = self.args['n_epoch']\n",
    "        if self.use_cuda:\n",
    "            self.clf =  self.net.apply(weight_reset).cuda()\n",
    "        else:\n",
    "            self.clf =  self.net.apply(weight_reset)\n",
    "\n",
    "        optimizer = optim.Adam(self.clf.parameters(), lr = self.args['lr'], weight_decay=0)\n",
    "        loader_tr = DataLoader(self.handler(self.X, self.Y, False),shuffle=True, batch_size = args['batch_size'])\n",
    "        epoch = 1\n",
    "        accCurrent = 0\n",
    "        while accCurrent < 0.95 and epoch < n_epoch: \n",
    "            accCurrent = self._train(epoch, loader_tr, optimizer)\n",
    "            epoch += 1\n",
    "            # print(str(epoch) + ' training accuracy: ' + str(accCurrent), flush=True)\n",
    "            \n",
    "            if (epoch % 50 == 0) and (accCurrent < 0.2): # resetif not converging\n",
    "                self.clf = self.net.apply(weight_reset)\n",
    "                optimizer = optim.Adam(self.clf.parameters(), lr = self.args['lr'], weight_decay=0)\n",
    "\n",
    "        print('Training accuracy:',round(accCurrent, 3)*100, flush=True) #'Epoch:', str(epoch),\n",
    "        return self.clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KrEWA8ln4BO"
   },
   "source": [
    "# **Trainig loop for active learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJIZ-mtqn3qQ"
   },
   "outputs": [],
   "source": [
    "def training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=False):\n",
    "\n",
    "    flag = False\n",
    "    if first:\n",
    "\n",
    "      nSamps, dim = np.shape(X_unlabeled)\n",
    "\n",
    "      np.random.seed(42)\n",
    "      start_idxs = np.random.choice(nSamps, size=int(0.01*nSamps), replace=False)\n",
    "\n",
    "      X_tr = X_unlabeled[start_idxs]\n",
    "      X_unlabeled = np.delete(X_unlabeled, start_idxs, axis = 0)\n",
    "\n",
    "      Y_tr = Y_unlabeled[start_idxs]\n",
    "      Y_unlabeled = np.delete(Y_unlabeled, start_idxs, axis = 0)\n",
    "\n",
    "      print('Starting set of points -', len(start_idxs))\n",
    "\n",
    "    else:    \n",
    "\n",
    "      #Human In Loop, Assuming user adds new labels here\n",
    "      idx = strategy.select(budget)\n",
    "      \n",
    "      #Adding new points to training set\n",
    "      X_tr = np.concatenate((X_tr, X_unlabeled[idx]), axis=0)\n",
    "      X_unlabeled = np.delete(X_unlabeled, idx, axis = 0)\n",
    "\n",
    "      Y_tr = np.concatenate((Y_tr, Y_unlabeled[idx]), axis = 0)\n",
    "      Y_unlabeled = np.delete(Y_unlabeled, idx, axis = 0)\n",
    "\n",
    "      print('Number of training points -',X_tr.shape[0])\n",
    "    \n",
    "    strategy.update_data(X_tr, Y_tr, X_unlabeled)\n",
    "    dt.update_data(X_tr, Y_tr)\n",
    "\n",
    "    clf = dt.train()\n",
    "    strategy.update_model(clf)\n",
    "    y_pred = strategy.predict(x_tst).numpy()\n",
    "    acc = round(1.0 * (y_tst == y_pred).sum().item() / len(y_tst), 3)\n",
    "    #print('Testing accuracy:', acc, flush=True)\n",
    "    if acc > 0.98:\n",
    "        flag = True\n",
    "        print('Testing accuracy reached above 98%')\n",
    "\n",
    "    return X_tr,Y_tr,X_unlabeled,Y_unlabeled,acc, flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szatqijFdS_g"
   },
   "source": [
    "# **Random**\n",
    "This strategy is often used as a baseline, where we pick a set of unlabled points randomly. Here we create a instance of distil.active_learning_strategies.random_sampling.RandomSampling by passig following parameters:\n",
    "\n",
    "**X (Numpy array)** – Features of the labled set of points\n",
    "\n",
    "**Y (Numpy array)** – Lables of the labled set of points\n",
    "\n",
    "**unlabeled_x (Numpy array)** – Features of the unlabled set of points\n",
    "\n",
    "**net (class object)** – Model architecture used for training. Could be instance of models defined in distil.utils.models or something similar.\n",
    "\n",
    "**handler (class object)** – It should be a subclass of torch.utils.data.Dataset i.e, have __getitem__ and __len__ methods implemented, so that is could be passed to pytorch DataLoader.Could be instance of handlers defined in distil.utils.DataHandler or something similar.\n",
    "\n",
    "**nclasses (int)** – No. of classes in tha dataset\n",
    "\n",
    "**args (dictionary)**– This dictionary should have ‘batch_size’ as a key. 'batch_size' should be such that one can exploit the benefits of tensorization while honouring the resourse constraits. This ‘batch_size’ therefore can be different than the one used for training.\n",
    "\n",
    "We initally pass None for X,Y and unlabeled_x. Later we update using update functions of training class and RandomSampling class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwOzGCfgcwTC",
    "outputId": "4a543cfd-2eac-4656-b4db-da1819d66b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting set of points - 350\n",
      "Training accuracy: 93.4\n",
      "Initial Testing accuracy: 91.4\n",
      "-------------------------------------------------\n",
      "Round 1\n",
      "-------------------------------------------------\n",
      "Number of training points - 700\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 1 round : 91.8\n",
      "-------------------------------------------------\n",
      "Round 2\n",
      "-------------------------------------------------\n",
      "Number of training points - 1050\n",
      "Training accuracy: 95.1\n",
      "Testing accuracy at 2 round : 92.30000000000001\n",
      "-------------------------------------------------\n",
      "Round 3\n",
      "-------------------------------------------------\n",
      "Number of training points - 1400\n",
      "Training accuracy: 95.19999999999999\n",
      "Testing accuracy at 3 round : 92.10000000000001\n",
      "-------------------------------------------------\n",
      "Round 4\n",
      "-------------------------------------------------\n",
      "Number of training points - 1750\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 4 round : 91.8\n",
      "-------------------------------------------------\n",
      "Round 5\n",
      "-------------------------------------------------\n",
      "Number of training points - 2100\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 5 round : 92.30000000000001\n",
      "-------------------------------------------------\n",
      "Round 6\n",
      "-------------------------------------------------\n",
      "Number of training points - 2450\n",
      "Training accuracy: 95.1\n",
      "Testing accuracy at 6 round : 92.7\n",
      "-------------------------------------------------\n",
      "Round 7\n",
      "-------------------------------------------------\n",
      "Number of training points - 2800\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 7 round : 92.60000000000001\n",
      "-------------------------------------------------\n",
      "Round 8\n",
      "-------------------------------------------------\n",
      "Number of training points - 3150\n",
      "Training accuracy: 95.19999999999999\n",
      "Testing accuracy at 8 round : 92.60000000000001\n",
      "-------------------------------------------------\n",
      "Round 9\n",
      "-------------------------------------------------\n",
      "Number of training points - 3500\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 9 round : 92.80000000000001\n",
      "-------------------------------------------------\n",
      "Round 10\n",
      "-------------------------------------------------\n",
      "Number of training points - 3850\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 10 round : 92.80000000000001\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(data_dims, num_cls,40)\n",
    "net.apply(init_weights)\n",
    "\n",
    "strategy_args = {'batch_size' : 1000} \n",
    "strategy = RandomSampling(None, None, None, net, DataHandler_Points, num_cls, strategy_args)\n",
    "\n",
    "args = {'n_epoch':150, 'lr':float(0.001),'batch_size':300}  #Different args than strategy_args\n",
    "n_rounds = 10    ##Number of rounds to run ac\n",
    "budget = int(0.01*x_trn.shape[0])    ##Number of new data points after every iteration\n",
    "\n",
    "#Training Class initialization\n",
    "dt = data_train(None, None, net, DataHandler_Points, args)\n",
    "\n",
    "rand_acc = np.zeros(n_rounds+1)\n",
    "X_unlabeled = deepcopy(x_trn)\n",
    "Y_unlabeled = deepcopy(y_trn)\n",
    "X_tr = None\n",
    "Y_tr = None\n",
    "\n",
    "X_tr,Y_tr,X_unlabeled,Y_unlabeled,rand_acc[0],_ = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=True)\n",
    "print('Initial Testing accuracy:', round(rand_acc[0], 3)*100, flush=True)\n",
    "\n",
    "for i in range(n_rounds):\n",
    "   print('-------------------------------------------------')\n",
    "   print('Round', i+1) \n",
    "   print('-------------------------------------------------')\n",
    "   \n",
    "   X_tr,Y_tr,X_unlabeled,Y_unlabeled,rand_acc[i+1],flag = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst)\n",
    "   print('Testing accuracy at',i+1,'round :', round(rand_acc[i+1], 3)*100, flush=True)  \n",
    "   \n",
    "   if flag:\n",
    "     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRm2tsuwqQEP"
   },
   "source": [
    "# **Uncertanity based Active learning Strategy**\n",
    "\n",
    "The most basic active learning strategy, where we select samples about which the model is most uncertain. To quantify the uncertainity we use entropy, therefore select points which have maximum entropy. Let $z_i$ be output from the model then the correponding softmax would be $$\\sigma(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}$$. Then entropy can be calculated as, $$ENTROPY = -\\sum_j \\sigma(z_j)*log(\\sigma(z_i))$$\n",
    "\n",
    "Here we create a instance of distil.active_learning_strategies.entropy_sampling.EntropySampling with same parameters passed to distil.active_learning_strategies.random_sampling.RandomSampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSBY1RRKqPye",
    "outputId": "6ce0f896-0a24-4847-b16a-9996dc889c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting set of points - 350\n",
      "Training accuracy: 93.4\n",
      "Initial Testing accuracy: 91.4\n",
      "-------------------------------------------------\n",
      "Round 1\n",
      "-------------------------------------------------\n",
      "Number of training points - 700\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 1 round : 94.5\n",
      "-------------------------------------------------\n",
      "Round 2\n",
      "-------------------------------------------------\n",
      "Number of training points - 1050\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 2 round : 95.8\n",
      "-------------------------------------------------\n",
      "Round 3\n",
      "-------------------------------------------------\n",
      "Number of training points - 1400\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 3 round : 97.1\n",
      "-------------------------------------------------\n",
      "Round 4\n",
      "-------------------------------------------------\n",
      "Number of training points - 1750\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 4 round : 97.6\n",
      "-------------------------------------------------\n",
      "Round 5\n",
      "-------------------------------------------------\n",
      "Number of training points - 2100\n",
      "Training accuracy: 92.80000000000001\n",
      "Testing accuracy at 5 round : 97.0\n",
      "-------------------------------------------------\n",
      "Round 6\n",
      "-------------------------------------------------\n",
      "Number of training points - 2450\n",
      "Training accuracy: 92.10000000000001\n",
      "Testing accuracy at 6 round : 96.8\n",
      "-------------------------------------------------\n",
      "Round 7\n",
      "-------------------------------------------------\n",
      "Number of training points - 2800\n",
      "Training accuracy: 91.9\n",
      "Testing accuracy at 7 round : 97.39999999999999\n",
      "-------------------------------------------------\n",
      "Round 8\n",
      "-------------------------------------------------\n",
      "Number of training points - 3150\n",
      "Training accuracy: 90.60000000000001\n",
      "Testing accuracy at 8 round : 97.2\n",
      "-------------------------------------------------\n",
      "Round 9\n",
      "-------------------------------------------------\n",
      "Number of training points - 3500\n",
      "Training accuracy: 90.9\n",
      "Testing accuracy at 9 round : 97.39999999999999\n",
      "-------------------------------------------------\n",
      "Round 10\n",
      "-------------------------------------------------\n",
      "Number of training points - 3850\n",
      "Training accuracy: 92.10000000000001\n",
      "Testing accuracy at 10 round : 97.7\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(data_dims, num_cls,40)\n",
    "net.apply(init_weights)\n",
    "\n",
    "strategy_args = {'batch_size' : 1000} \n",
    "strategy = EntropySampling(None, None, None, net, DataHandler_Points, num_cls, strategy_args)\n",
    "\n",
    "args = {'n_epoch':150, 'lr':float(0.001),'batch_size':300}  #Different args than strategy_args\n",
    "n_rounds = 10    ##Number of rounds to run ac\n",
    "budget = int(0.01*x_trn.shape[0])    ##Number of new data points after every iteration\n",
    "\n",
    "#Training Class initialization\n",
    "dt = data_train(None, None, net, DataHandler_Points, args)\n",
    "\n",
    "un_acc = np.zeros(n_rounds+1)\n",
    "X_unlabeled = deepcopy(x_trn)\n",
    "Y_unlabeled = deepcopy(y_trn)\n",
    "X_tr = None\n",
    "Y_tr = None\n",
    "\n",
    "X_tr,Y_tr,X_unlabeled,Y_unlabeled,un_acc[0],_ = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=True)\n",
    "print('Initial Testing accuracy:', round(un_acc[0], 3)*100, flush=True)\n",
    "\n",
    "for i in range(n_rounds):\n",
    "   print('-------------------------------------------------')\n",
    "   print('Round', i+1) \n",
    "   print('-------------------------------------------------')\n",
    "   \n",
    "   X_tr,Y_tr,X_unlabeled,Y_unlabeled,un_acc[i+1],flag = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst)\n",
    "   print('Testing accuracy at',i+1,'round :', round(un_acc[i+1], 3)*100, flush=True)  \n",
    "   \n",
    "   if flag:\n",
    "     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C-rsSkOqdKA"
   },
   "source": [
    "# **GLISTER**\n",
    "This is implemetation of GLISTER-ACTIVE from the paper [GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning](https://arxiv.org/abs/2012.10630). GLISTER methods tries to solve a bi-level optimisation problem.\n",
    "\\begin{equation*}\n",
    "\\overbrace{\\underset{{S \\subseteq {\\mathcal U}, |S| \\leq k}}{\\operatorname{argmax\\hspace{0.7mm}}} LL_V(\\underbrace{\\underset{\\theta}{\\operatorname{argmax\\hspace{0.7mm}}} LL_T( \\theta, S)}_{inner-level}, {\\mathcal V})}^{outer-level}\n",
    "\\end{equation*}\n",
    "where is $S$ is set of points selected at each round,${\\mathcal V}$ could be a dedicated validation set with labled points or could be union of labeled and unlabeled points with hypothesised labels, $k$ is the budget.\n",
    "To set ${\\mathcal V}$ to be validation set, while calling **GLISTER** class in the toolkit set _valid=TRUE_ and pass validation set otherwise set _valid=False_.\n",
    "\n",
    "Solving this problem directly is almost impossible, therefore we resort to one-step approxiations.We start we $S^0$ as empty set and bulid it as $S^k = S^{k-1} \\cup e$, where $e$ is $\\underset{e}{\\operatorname{argmax\\hspace{0.7mm}}} G_{\\theta}(e | S^k)$. We define,$$G_{\\theta}(e | S^k) = LL_{V}(\\theta^{k}, {\\mathcal V})$$ and update $$\\theta^k \\leftarrow \\theta^{k-1} -  \\eta \\nabla_{\\theta} LL_T(\\hat{\\theta}, e)$$ where $\\hat{\\theta}$ is the parameters of the model at the begining of the selection.\n",
    "To prevent overfitting, we can add regularizer to GLISTER, which can be set by **_typeOf_**. **_typeOf_** can be set to - **'none'**(which is default) for normal GLISTER,**'Rand'** for replacing **_lam_** fraction of points replaced by random points, **'Diversity'** adding diversity set function while computing gain and **'FacLoc'** adding Facility Location set function while computing gain. **_lam_** for both **'Diversity'** and **'FacLoc'** determines the weightage given to them while computing the gain.\n",
    "\n",
    "Here we create a instance of distil.active_learning_strategies.glister.GLISTER( with same parameters passed to distil.active_learning_strategies.random_sampling.RandomSampling, we slight change that, **args** dictionary should have keys ‘batch_size’ and ‘lr’. ‘lr’ should be the learning rate used for training. In addition to those folowing additional parameters may be passed:\n",
    "\n",
    "**valid (boolean)** – Whether validation set is passed or not\n",
    "\n",
    "**X_val (Numpy array, optional)** – Features of the points in the validation set. Mandatory if valid=True.\n",
    "\n",
    "**Y_val (Numpy array, optional)** – Lables of the points in the validation set. Mandatory if valid=True.\n",
    "\n",
    "**loss_criterion (class object, optional)** – The type of loss criterion. Default is torch.nn.CrossEntropyLoss()\n",
    "\n",
    "**typeOf (str, optional)** – Determines the type of regulariser to be used. Default is ‘none’. For random regulariser use ‘Rand’. To use Facility Location set functiom as a regulariser use ‘FacLoc’. To use Diversity set functiom as a regulariser use ‘Diversity’.\n",
    "\n",
    "**lam (float, optional)** – Determines the amount of regularisation to be applied. Mandatory if is not typeOf=’none’ and by default set to None. For random regulariser use values should be between 0 and 1 as it determines fraction of points replaced by random points. For both ‘Diversity’ and ‘FacLoc’ lam determines the weightage given to them while computing the gain.\n",
    "\n",
    "**kernel_batch_size (int, optional)** – For 'Diversity' and 'FacLoc' regualrizer versions, similarity kernel is to be computed, which entails creating a 3d torch tensor of dimenssions $kernel\\_batch\\_size^{2}*(feature\\ dimenssion)$. Again kernel_batch_size should be such that one can exploit the benefits of tensorization while honouring the resourse constraits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_gJF_i7TdrD",
    "outputId": "53b1e0ac-2387-49d8-df8e-38fe4b999ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting set of points - 350\n",
      "Training accuracy: 93.4\n",
      "Initial Testing accuracy: 91.4\n",
      "-------------------------------------------------\n",
      "Round 1\n",
      "-------------------------------------------------\n",
      "Number of training points - 700\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 1 round : 92.60000000000001\n",
      "-------------------------------------------------\n",
      "Round 2\n",
      "-------------------------------------------------\n",
      "Number of training points - 1050\n",
      "Training accuracy: 94.19999999999999\n",
      "Testing accuracy at 2 round : 94.69999999999999\n",
      "-------------------------------------------------\n",
      "Round 3\n",
      "-------------------------------------------------\n",
      "Number of training points - 1400\n",
      "Training accuracy: 95.0\n",
      "Testing accuracy at 3 round : 95.89999999999999\n",
      "-------------------------------------------------\n",
      "Round 4\n",
      "-------------------------------------------------\n",
      "Number of training points - 1750\n",
      "Training accuracy: 93.30000000000001\n",
      "Testing accuracy at 4 round : 96.39999999999999\n",
      "-------------------------------------------------\n",
      "Round 5\n",
      "-------------------------------------------------\n",
      "Number of training points - 2100\n",
      "Training accuracy: 93.0\n",
      "Testing accuracy at 5 round : 97.5\n",
      "-------------------------------------------------\n",
      "Round 6\n",
      "-------------------------------------------------\n",
      "Number of training points - 2450\n",
      "Training accuracy: 90.60000000000001\n",
      "Testing accuracy at 6 round : 96.89999999999999\n",
      "-------------------------------------------------\n",
      "Round 7\n",
      "-------------------------------------------------\n",
      "Number of training points - 2800\n",
      "Training accuracy: 91.8\n",
      "Testing accuracy at 7 round : 97.3\n",
      "-------------------------------------------------\n",
      "Round 8\n",
      "-------------------------------------------------\n",
      "Number of training points - 3150\n",
      "Training accuracy: 91.9\n",
      "Testing accuracy at 8 round : 97.1\n",
      "-------------------------------------------------\n",
      "Round 9\n",
      "-------------------------------------------------\n",
      "Number of training points - 3500\n",
      "Training accuracy: 91.5\n",
      "Testing accuracy at 9 round : 97.39999999999999\n",
      "-------------------------------------------------\n",
      "Round 10\n",
      "-------------------------------------------------\n",
      "Number of training points - 3850\n",
      "Training accuracy: 91.5\n",
      "Testing accuracy at 10 round : 97.8\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(data_dims, num_cls,40)\n",
    "net.apply(init_weights)\n",
    "\n",
    "strategy_args = {'batch_size' : 12000, 'lr':float(0.001)} \n",
    "strategy = GLISTER(None, None, None, net, DataHandler_Points, num_cls, strategy_args,valid=False,typeOf='Diversity',lam=20)\n",
    "\n",
    "args = {'n_epoch':150, 'lr':float(0.001),'batch_size':300}  #Different args than strategy_args\n",
    "n_rounds = 10    ##Number of rounds to run ac\n",
    "budget = int(0.01*x_trn.shape[0])     ##Number of new data points after every iteration\n",
    "\n",
    "#Training Class initialization\n",
    "dt = data_train(None, None, net, DataHandler_Points, args)\n",
    "\n",
    "glister_acc = np.zeros(n_rounds+1)\n",
    "X_unlabeled = deepcopy(x_trn)\n",
    "Y_unlabeled = deepcopy(y_trn)\n",
    "X_tr = None\n",
    "Y_tr = None\n",
    "\n",
    "X_tr,Y_tr,X_unlabeled,Y_unlabeled,glister_acc[0],_ = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=True)\n",
    "print('Initial Testing accuracy:', round(glister_acc[0], 3)*100, flush=True)\n",
    "\n",
    "for i in range(n_rounds):\n",
    "  \n",
    "  print('-------------------------------------------------')\n",
    "  print('Round', i+1) \n",
    "  print('-------------------------------------------------')\n",
    "\n",
    "  X_tr,Y_tr,X_unlabeled,Y_unlabeled,glister_acc[i+1],flag = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst)\n",
    "  print('Testing accuracy at',i+1,'round :', round(glister_acc[i+1], 3)*100, flush=True)  \n",
    "  if flag:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwrpLSGRUYZw"
   },
   "source": [
    "# **BADGE**\n",
    "This method is based on the paper [Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds](https://arxiv.org/abs/1906.03671). Here at each around of selection loss gradients are computed using the hypothesised lables. Then to points to be labled are selected by applying k-means++ on these loss gradients. \n",
    "\n",
    "Here we create a instance of distil.active_learning_strategies.badge.BADGE with same parameters passed to distil.active_learning_strategies.random_sampling.RandomSampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEtuF8O29fwh",
    "outputId": "c93db8f2-7fde-4459-f8e8-bcf4d909be13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting set of points - 350\n",
      "Training accuracy: 93.4\n",
      "Initial Testing accuracy: 91.4\n",
      "-------------------------------------------------\n",
      "Round 1\n",
      "-------------------------------------------------\n",
      "Number of training points - 700\n",
      "Training accuracy: 94.0\n",
      "Testing accuracy at 1 round : 94.1\n",
      "-------------------------------------------------\n",
      "Round 2\n",
      "-------------------------------------------------\n",
      "Number of training points - 1050\n",
      "Training accuracy: 93.89999999999999\n",
      "Testing accuracy at 2 round : 95.39999999999999\n",
      "-------------------------------------------------\n",
      "Round 3\n",
      "-------------------------------------------------\n",
      "Number of training points - 1400\n",
      "Training accuracy: 94.6\n",
      "Testing accuracy at 3 round : 96.2\n",
      "-------------------------------------------------\n",
      "Round 4\n",
      "-------------------------------------------------\n",
      "Number of training points - 1750\n",
      "Training accuracy: 94.3\n",
      "Testing accuracy at 4 round : 96.89999999999999\n",
      "-------------------------------------------------\n",
      "Round 5\n",
      "-------------------------------------------------\n",
      "Number of training points - 2100\n",
      "Training accuracy: 93.89999999999999\n",
      "Testing accuracy at 5 round : 97.0\n",
      "-------------------------------------------------\n",
      "Round 6\n",
      "-------------------------------------------------\n",
      "Number of training points - 2450\n",
      "Training accuracy: 92.4\n",
      "Testing accuracy at 6 round : 96.89999999999999\n",
      "-------------------------------------------------\n",
      "Round 7\n",
      "-------------------------------------------------\n",
      "Number of training points - 2800\n",
      "Training accuracy: 94.5\n",
      "Testing accuracy at 7 round : 97.5\n",
      "-------------------------------------------------\n",
      "Round 8\n",
      "-------------------------------------------------\n",
      "Number of training points - 3150\n",
      "Training accuracy: 93.7\n",
      "Testing accuracy at 8 round : 97.39999999999999\n",
      "-------------------------------------------------\n",
      "Round 9\n",
      "-------------------------------------------------\n",
      "Number of training points - 3500\n",
      "Training accuracy: 92.60000000000001\n",
      "Testing accuracy at 9 round : 97.1\n",
      "-------------------------------------------------\n",
      "Round 10\n",
      "-------------------------------------------------\n",
      "Number of training points - 3850\n",
      "Training accuracy: 93.5\n",
      "Testing accuracy at 10 round : 97.6\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(data_dims, num_cls,40)\n",
    "net.apply(init_weights)\n",
    "\n",
    "strategy_args = {'batch_size' : 12000} \n",
    "strategy = BADGE(None, None, None, net, DataHandler_Points, num_cls, strategy_args)\n",
    "\n",
    "args = {'n_epoch':150, 'lr':float(0.001),'batch_size':300}  #Different args than strategy_args\n",
    "n_rounds = 10    ##Number of rounds to run ac\n",
    "budget = int(0.01*x_trn.shape[0])     ##Number of new data points after every iteration\n",
    "\n",
    "#Training Class initialization\n",
    "dt = data_train(None, None, net, DataHandler_Points, args)\n",
    "\n",
    "badge_acc = np.zeros(n_rounds+1)\n",
    "X_unlabeled = deepcopy(x_trn)\n",
    "Y_unlabeled = deepcopy(y_trn)\n",
    "X_tr = None\n",
    "Y_tr = None\n",
    "\n",
    "X_tr,Y_tr,X_unlabeled,Y_unlabeled,badge_acc[0],_ = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst,first=True)\n",
    "print('Initial Testing accuracy:', round(badge_acc[0], 3)*100, flush=True)\n",
    "\n",
    "for i in range(n_rounds):\n",
    "  print('-------------------------------------------------')\n",
    "  print('Round', i+1) \n",
    "  print('-------------------------------------------------')\n",
    "\n",
    "  X_tr,Y_tr,X_unlabeled,Y_unlabeled,badge_acc[i+1],flag = training_round(strategy,dt,X_tr,Y_tr,X_unlabeled,Y_unlabeled,x_tst,y_tst)\n",
    "  print('Testing accuracy at',i+1,'round :', round(badge_acc[i+1], 3)*100, flush=True)  \n",
    "  if flag:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "Hd8PpgnYAYAW",
    "outputId": "e7780ae1-da89-44db-a22f-871de7a8634b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'IJCNN1')"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.array([budget for i in range(n_rounds+1)])\n",
    "x_axis = x_axis*np.array([i for i in range(1,n_rounds+2)])\n",
    "plt.figure()\n",
    "plt.plot(x_axis, glister_acc*100, 'b-', label='GLISTER-Diversity',marker='o')\n",
    "plt.plot(x_axis, un_acc*100, 'g-', label='Uncertanity',marker='o')\n",
    "plt.plot(x_axis, badge_acc*100, 'c', label='BADGE',marker='o')\n",
    "plt.plot(x_axis, rand_acc*100, 'r', label='Random',marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('No of points')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('IJCNN1')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DISTIL_DEMO_IJCNN1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
